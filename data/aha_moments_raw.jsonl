{"source": "HackerNews", "title": "Show HN: Pluto \u2013 AI for investing, data visualization, automation and analysis", "text": "Hey HN! I&#x27;m Jacob Sansbury, a software developer and founder of Pluto. After working at Bridgewater Associates and moving to San Francisco, I decided to combine my passion for software development and finance to create Pluto \u2013 an AI-driven platform that revolutionizes the way retail investors manage their finances. Today, I&#x27;m excited to share our beta with you:<p><a href=\"https:&#x2F;&#x2F;pluto.fi&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;pluto.fi&#x2F;</a><p>Pluto is built with a combination of Next.js and Python, running on K8s and Kafka. Our AI Copilot, Plato, uses a three-part system (thinkers, actors, and communicators) to analyze data, execute actions, and communicate results to the user.<p>1. Thinkers: These components are responsible for gathering data and generating observations about the world. They query various data sources, such as financial markets, news feeds, or user inputs, to create specific observations (e.g., &quot;AAPL&#x27;s price is $132&quot;). The thinkers act as the &quot;eyes and ears&quot; of the AI system, providing the essential information needed for decision-making.<p>2. Actors: The actors take the observations generated by the thinkers and use them to execute actions that change the state of the world or the system. These actions can include creating new investment strategies, adjusting existing strategies, executing trades, or running tests. The actors are the &quot;doers&quot; in the system, responsible for making things happen based on the information they receive.<p>3. Communicators: The communicators are responsible for wrapping up the observations and actions and presenting them to the user in a clear and understandable format. They may generate reports, send notifications, or provide visualizations to help users make sense of what the AI system has done. The communicators act as the &quot;voice&quot; of the AI system, bridging the gap between the raw data and the user&#x27;s understanding.<p>We&#x27;ve faced several i", "url": "https://www.pluto.fi", "hn_url": "https://news.ycombinator.com/item?id=36257291", "score": 7, "num_comments": 9, "created_utc": 1686316164, "author": "jsnns", "ai_tool": "Copilot", "scraped_at": "2025-12-17T17:19:02.757528"}
{"source": "HackerNews", "title": "Show HN: Rtrvr.ai \u2013 Remote Control Your Browser with an AI Web Agent and MCP", "text": "Hey HN, I&#x27;m Arjun, one of the founders of rtrvr.ai.<p>For the past year, we&#x27;ve been building and iterating on an in-browser AI agent. But a few months ago, we hit a wall in our approach and decided to tear everything down and rebuild from first principles. The result is what we&#x27;re re-launching today.<p>The Problem&#x2F;Insight:\nWe kept coming back to a simple, nagging question: web agents by themselves are a nice to have but we kept getting requests on possible ways to integrate or call our agent from another agent. Users also kept asking to reuse their own existing chatbot subscriptions to power the agent.<p>The &quot;Aha!&quot; Moment with MCP:\nThis led us down the rabbit hole of interoperability and we landed on MCP. Our core insight was this: what if we exposed the Chrome Extension itself as a Remote MCP server?<p>This simple idea completely changed our architecture and value proposition. It turns the user&#x27;s browser into a controllable, sandboxed endpoint that any other AI can talk to with a simple copy&#x2F;paste of a MCP url.<p>What this new architecture unlocks:\nRemote Control Your Browser: You can stay in your flow in Claude and tell it to perform tasks on your behalf in background tabs. No more context switching. Tell Claude to file that Jira ticket or scrape a site without ever leaving the chat.<p>Reuse Your Own Subscription (The &quot;BYO-Sub&quot; model): Since Claude is driving the action, you&#x27;re using your existing subscription to power the agent for basic tasks. We see this as the future \u2013 our agent provides the secure execution rails, and you bring the brain you already pay for. Users can then upgrade to our more advanced, multi-step agent for complex workflows when needed.<p>Our Bigger Bet - The Agentic Web:\nWe believe the future isn&#x27;t a single &quot;god agent&quot; but a network of specialized agents that collaborate. By exposing the browser as a common execution layer, we&#x27;re hoping to provide the &quot;rails&quot", "url": "https://www.rtrvr.ai", "hn_url": "https://news.ycombinator.com/item?id=45898043", "score": 6, "num_comments": 3, "created_utc": 1762939019, "author": "arjunchint", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.757587"}
{"source": "HackerNews", "title": "Top Developer Articles of the Week on CoderLegion", "text": "Top 5 Developer Articles of the Week on CoderLegion<p>Every week, the CoderLegion community brings together developers from around the world to share practical insights, experiments, and honest experiences from the trenches of coding.<p>Here are the five posts that made the most impact this week \u2014 whether through comments, reads, or shares \u2014 all written by real developers who love to build and learn.<p>1\u20e3 Null: The Billion Dollar Mistake<p>by Max Contieri\nRead the full article \u2192 https:&#x2F;&#x2F;coderlegion.com&#x2F;6462&#x2F;null-the-billion-dollar-mistake\nSometimes the biggest performance wins come from rethinking your tooling. Tony shares how embracing safer patterns around null references can drastically reduce production incidents \u2014 and what trade-offs came with it. A must-read for anyone still battling NPEs.<p>2\u20e3 Vibe coding is bullshit if you don\u2019t know what you\u2019re doing<p>by Kenliten\nRead the full article \u2192 https:&#x2F;&#x2F;coderlegion.com&#x2F;6497&#x2F;vibe-coding-is-bullshit-if-you-dont-know-what-youre-doing\nReadable code doesn\u2019t just improve quality \u2014 it preserves sanity. Ken breaks down why \u201cvibe-coding\u201d (jumping straight into AI-scaffolded apps) may look fast but can cost you maintainability, clarity, and long-term control.<p>3\u20e3 The post compares G1, ZGC and Shenandoah Java garbage collectors<p>by webMethodMan\nRead the full article \u2192 https:&#x2F;&#x2F;coderlegion.com&#x2F;6543&#x2F;the-post-compares-g1-zgc-and-shenandoah-java-garbage-collectors\nAI tools like Copilot and ChatGPT are reshaping how we code \u2014 but should we be worried or excited? This deep dive sparked major debate this week on how developers can adapt GC tools, choose the right collector, and manage performance in large-scale Java apps.<p>4\u20e3 My SQL Mistakes Almost Broke Me\u2026 But I Learned a Lot<p>by DuchessCodes\nRead the full article \u2192 https:&#x2F;&#x2F;coderlegion.com&#x2F;6542&#x2F;my-sql-mistakes-almost-broke-me-but-i-learned-a-lot\nRust can be intimidating at first, but DuchessCodes\u2019s ", "url": "https://news.ycombinator.com/item?id=45701753", "hn_url": "https://news.ycombinator.com/item?id=45701753", "score": 2, "num_comments": 0, "created_utc": 1761374032, "author": "kodwings", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.757606"}
{"source": "HackerNews", "title": "Ask HN: What are your key use cases for bulk YouTube subtitle downloading?", "text": "Hey everyone,<p>I&#x27;m the creator of YTVidHub (a simple tool for downloading YT subtitles, now adding proper bulk support). Before I finalize the paid tiers and future features (like better AI transcription), I&#x27;m doing a quick community survey to make sure I&#x27;m building what people actually need.<p>My early assumption was that most users are casual language learners, but I recently got feedback from a user who needs to download hundreds of files to feed into an LLM for Mandarin research. That was a huge &quot;Aha!&quot; moment for me.<p>So, if you currently bulk download subtitles, or if you&#x27;ve ever wished you could, what are your core needs?<p>1.  Use Cases: What drives your frequent, bulk download needs? (e.g., academic research, competitor analysis, creating translations for niche languages, language immersion, etc.)\n2.  Volume &amp; Frequency: How many videos do you typically need to process in a single batch, and how often do you need that capacity? (e.g., 500 URLs once a month; 100 URLs every week).\n3.  Technical Pain Points: Are there any frustrating technical issues you constantly run into? (e.g., poor AI quality in certain languages, handling timestamps, getting clean JSON output, hitting API rate limits).<p>Any insights, technical issues, or feature requests you share will be incredibly helpful and directly guide the product&#x27;s roadmap.<p>Thanks in advance for sharing your knowledge!", "url": "https://news.ycombinator.com/item?id=45589199", "hn_url": "https://news.ycombinator.com/item?id=45589199", "score": 2, "num_comments": 0, "created_utc": 1760513671, "author": "Franklinjobs617", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.757623"}
{"source": "HackerNews", "title": "HN: Solo founder building \"GTM agent swarm\" \u2013 anyone else?", "text": "Hey HN<p>Solo founder here, working on fosic.ai - my project for orchestrating go-to-market (GTM) with a \u201cswarm\u201d of super-specialized AI agents (think: automating sales, research, content, GEO, etc.), without hiring a team.<p>Right now, I\u2019m fully in vibe coding mode\u2014building everything on Replit and getting a ton of help from Perplexity Pro as my \u201csidekick.\u201d I&#x27;m not a developer. I do have 22 yrs of B2B go-to-market experience though so I know the jobs-to-be-done quite well and have worked in tech and as a consultant for 8 years. Still constantly wondering if I\u2019m making things too complicated with all these agents, instead of just keeping it simple. My hope is to see if a solo founder can really punch above their weight class by working this way, but I\u2019m still pre-launch.<p>Anyone else experimenting with stacking AI agents for GTM (or ops&#x2F;marketing&#x2F;founder tasks in general), or just thinking about it? What are your hopes, doubts, or \u201caha\u201d moments? If you\u2019ve got stories\u2014from \u201cthat\u2019ll never work\u201d to \u201cit finally clicked\u201d would love to hear them.<p>Would also be grateful for any advice from people a bit further ahead (especially other solos), hit any major roadblocks, or did anything surprise you about working this way?<p>Happy to share more on what I\u2019m building (or not, if that\u2019s too pitchy). Just excited to see if others are thinking down these lines too!<p>PS: if you are a developer and would like to give your 2 cents of how I should go about it, I am all ears. Cheers.", "url": "https://news.ycombinator.com/item?id=44939958", "hn_url": "https://news.ycombinator.com/item?id=44939958", "score": 1, "num_comments": 1, "created_utc": 1755521102, "author": "johnathan_p", "ai_tool": "Perplexity", "scraped_at": "2025-12-17T17:19:02.757677"}
{"source": "HackerNews", "title": "Zed's Pricing Has Changed: LLM Usage Is Now Token-Based", "text": "", "url": "https://zed.dev/blog/pricing-change-llm-usage-is-now-token-based", "hn_url": "https://news.ycombinator.com/item?id=45362425", "score": 182, "num_comments": 197, "created_utc": 1758730429, "author": "meetpateltech", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.757693"}
{"source": "HackerNews", "title": "Ask HN: Has LLM prompting changed how you interact with people?", "text": "A few times now, I&#x27;ve realized that something I was going to say to someone was going to not add meaningful enough information to include it in a conversation.<p>That just by uttering the thing it would unnecessarily cloud the person&#x27;s &quot;context.&quot; Even if it seemed innocuous.<p>I&#x27;ve gotten surgical in how I handle LLM conversation contexts, and I think I&#x27;m paying more careful attention to what I say from that.<p>I&#x27;m curious if this has happened to anyone else.", "url": "https://news.ycombinator.com/item?id=44009819", "hn_url": "https://news.ycombinator.com/item?id=44009819", "score": 2, "num_comments": 2, "created_utc": 1747429521, "author": "bredren", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.757701"}
{"source": "HackerNews", "title": "Ask HN: Has working with LLMs changed your cognition?", "text": "", "url": "https://news.ycombinator.com/item?id=44281988", "hn_url": "https://news.ycombinator.com/item?id=44281988", "score": 2, "num_comments": 1, "created_utc": 1749990742, "author": "squircle", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.757709"}
{"source": "HackerNews", "title": "Show HN: GitHits \u2013 Code example engine for AI agents and devs (Private Beta)", "text": "It has been almost 10 years since I started the opencv-python packaging project. Scaling it to more than 100 million downloads as a side project showed me how much ease of installation and proper package distribution matter to users. It gave the computer vision ecosystem a noticeable boost. Now I have a new idea that I hope can help even more people across the broader software engineering world.<p>A while ago, I realized I kept giving the same advice to teammates and friends when they ran into a programming issue they couldn&#x27;t easily solve: go to GitHub and look at how others solved it.<p>There is a huge pool of underused example material across open source. Most problems developers face are not that novel. With enough digging, someone has already solved the same issue in code or at least posted a workaround to an issue or discussion thread.<p>The trouble is that GitHub search is limited and works only when you already know the right keywords. You also need the time and patience to go through and read all the results, connect information across files, repositories, issues, discussions, and other metadata, and then turn that into a working solution. The same limitations apply to Stack Overflow and other search tools.<p>LLMs changed a lot, but they did not change this. They do not perform equally well across all programming languages, and their training data is always stale. They cannot reliably show how to combine multiple libraries in the way real projects do. For these and many other cases, they need a real, canonical code example rather than an outdated piece of documentation written for humans.<p>That is why I started building GitHits. It is designed to handle the work that humans and AI coding agents struggle with: finding real solutions in real repositories and connecting the dots across the open source ecosystem.<p>GitHits searches millions of open-source repositories at the code level, finds real code and surrounding metadata that match the intent of you", "url": "https://githits.com/", "hn_url": "https://news.ycombinator.com/item?id=46105112", "score": 11, "num_comments": 4, "created_utc": 1764579592, "author": "skvark", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.757722"}
{"source": "HackerNews", "title": "Show HN: Mixpanel for Voice AI Agents", "text": "Hi, I\u2019m Tom Shapland, the cofounder of Canonical AI.<p>LLMs have changed the paradigm for Voice AI. Compared to rule-based systems (Siri, Alexa, Amazon Polly), LLM-based Voice AI agents understand the intent of the caller and can more often resolve the issue without escalation to a human agent.  Moreover, with LLM-based Voice AI agents, developers can build a Voice AI agent more quickly, onboard customers quicker, and iterate on the product faster. Our customers\u2019 Voice AI agents are doing amazing things. It\u2019s so much fun to see the agents achieve the caller\u2019s objective, even in the face of skepticism from the caller.<p>But LLM-based Voice AI agents are still nascent in some ways. For example, it\u2019s hard for developers to know how their agents are performing.  Most Voice AI agent developers are manually listening to calls to identify issues in them. Or they\u2019re finding out about issues with their agent when their customers complain. There\u2019s a better way.<p>When my cofounder, Adrian Cowham, and I started the company, we were building a semantic cache. We started meeting a lot of Voice AI developers because they were interested in latency improvements from caching. However, we kept hearing them say, \u201cWe don\u2019t need to optimize our agent yet. We just need to get it to be more reliable.\u201d<p>So we pivoted. We\u2019re now building Mixpanel for Voice AI agents. We map caller journeys. We provide audio metrics (i.e., latency) and conversational metrics (i.e., identify calls that end abruptly). We help Voice AI developers improve their agents.<p>We\u2019d love it if people in the Hacker News community would try out our product and let us know what they think!<p>Tom<p><a href=\"https:&#x2F;&#x2F;x.com&#x2F;tom_shapland\" rel=\"nofollow\">https:&#x2F;&#x2F;x.com&#x2F;tom_shapland</a>", "url": "https://voice.canonical.chat/", "hn_url": "https://news.ycombinator.com/item?id=41872964", "score": 5, "num_comments": 2, "created_utc": 1729193462, "author": "tmshapland", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.757735"}
{"source": "HackerNews", "title": "Show HN: Interfaze \u2013 The LLM Built for Developers", "text": "LLMs have changed the way we code, build, and launch a product. Many of these cases are human-in-the-loop tasks like vibe coding or workflows that have a larger margin of error that is acceptable.<p>However, LLMs aren&#x27;t great for backend developer tasks that have no&#x2F;low human in the loop, like OCR for KYC or web scraping structured data consistently or classification. Doing all this at scale and expecting the same results&#x2F;consistently is difficult.<p>We initially built JigsawStack to solve this problem by building small models with each model having a strong focus on doing one thing and doing that one thing very well. Then we saw majority of users would plug JigsawStack as a tool to an LLM.<p>We saw this and thought what we could train a general developer-focused LLM combining all our learnings from JigsawStack, with all the tools a developer would need from web search to proxy-based scraping, code execution, and more.<p>We just launched Interfaze in closed alpha, and we&#x27;re actively approving waitlist for your feedback so we can tune it to be just right for every developer\u2019s use case.", "url": "https://interfaze.ai", "hn_url": "https://news.ycombinator.com/item?id=45118425", "score": 3, "num_comments": 1, "created_utc": 1756920726, "author": "ykjs", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.757748"}
{"source": "HackerNews", "title": "Show HN: GrokVocab \u2013 I Built a Vocabulary App Without Flashcards or Memorization", "text": "Hi HN,<p>As a non-native speaker, I improved my vocabulary by reading English novels. At the time, it felt like a clever hack. It was hard and sometimes took me hours to read a single page(because I had to constantly look up words), but I pushed through because I enjoyed reading, especially fiction. I would never have put in the same effort to create flashcards or word lists and then memorize words. Learning works for me when it becomes a side effect of something engaging. Even now, if I want to learn a new programming language or framework, I skim the basics, pick a small project, and learn while building it rather than going through elaborate tutorials.<p>Coming back to vocabulary, while reading books worked well for me, I realize it doesn&#x27;t work for everyone. Many people don\u2019t enjoy reading even in their native language. When they see a wall of text, they instantly switch to TLDR mode. I&#x27;ve always been interested in novel ways of learning instead of rote memorization. I especially wanted to help vocabulary learners because the method I used truly worked for me. Also, the ability to read English effortlessly opened many doors for me.<p>My idea was to help users learn words in real context, focusing on the context first rather than on individual words like flashcards do. But instead of longer texts or books, the context should be bite-sized and engaging. I had tried to build small apps and prototypes around this idea in the past, but they didn\u2019t work well enough. The arrival of LLMs changed everything. If they are good at one thing, it\u2019s generating text. I experimented a bit, the results were promising, and I finally developed this app.<p>The idea is simple. Users read a short passage and try to understand it. When they encounter unfamiliar words, they can guess their meanings. Below the passage, users can check whether their guesses were right. Irrespective of whether they get it right or not, they get a memorable context that makes the word stick far be", "url": "https://www.grokvocab.com", "hn_url": "https://news.ycombinator.com/item?id=44543063", "score": 2, "num_comments": 0, "created_utc": 1752337010, "author": "ilamparithi", "ai_tool": "Grok", "scraped_at": "2025-12-17T17:19:02.757773"}
{"source": "HackerNews", "title": "Ask HN: How often do you settle technical debates with LLMs?", "text": "I&#x27;m curious whether&#x2F;how LLMs have changed technical debates inside dev teams.<p>Do you find that an LLM&#x27;s opinion on a technical debate is influential in the team? Is anyone swayed by it? Do you use an LLM to help form your technical arguments (to fact-find, etc. not necessarily to write the argument for you). Do you find LLMs opinionated enough to weigh in, or do they just recap the pros and cons? Have you seen other changes in team dynamics due to LLMs?", "url": "https://news.ycombinator.com/item?id=44218126", "hn_url": "https://news.ycombinator.com/item?id=44218126", "score": 1, "num_comments": 3, "created_utc": 1749402219, "author": "GMoromisato", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.757788"}
{"source": "HackerNews", "title": "Ask HN: How are you using LLM's that has changed your life?", "text": "", "url": "https://news.ycombinator.com/item?id=39731580", "hn_url": "https://news.ycombinator.com/item?id=39731580", "score": 3, "num_comments": 2, "created_utc": 1710644867, "author": "WheelsAtLarge", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.757796"}
{"source": "HackerNews", "title": "Ask HN: Have software interviews changed since LLMs?", "text": "I&#x27;m directing this question at folks who have done the interview circuit pre-LLMs and have recently interviewed.  Are companies still doing whiteboard algorithm interviews?  (I&#x27;m not so much looking for opinions or theories.  I&#x27;m just curious if there has been a noticeable change?)", "url": "https://news.ycombinator.com/item?id=39918894", "hn_url": "https://news.ycombinator.com/item?id=39918894", "score": 3, "num_comments": 0, "created_utc": 1712158783, "author": "stevehiehn", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.757802"}
{"source": "HackerNews", "title": "Tell HN: Sadly, my blog post's title was moderated", "text": "I&#x27;m the author of a post that reached HN top #2 today with the spicy title &quot;The AI Crowd is Mad.&quot;<p>A quick analysis that lead me to this title:<p>CTR is paramount to getting people to read your posts these days. Everybody linkbaits and so while I don&#x27;t even want to dramatize my titles, this is just what everybody has to do to get a foothold in global competition. It isn&#x27;t something I can change.<p>I had thought of a few titles before hand like: &quot;AI is boiling our oceans,&quot; &quot;AI is now in a Bubble&quot; and finally &quot;The AI Crowd is Mad.&quot;<p>I choose the later as it combines a mixture of touching people in their belief, behavior and belonging. &quot;The crowd is mad,&quot; is a contrarian view to &quot;the crowd is smart&quot; and so those that train AI models implicitly assume it. It&#x27;s a meaningful criticism that wants to tackle their presumptions. I&#x27;m really in doubt whether crowds are smart...<p>&quot;The AI Crowd is Mad,&quot; is also a hint at the post&#x27;s content in which I argue for the inflated expectations that investors have towards AI (and that it could be in a bubble).<p>I spent a significant time playing with titles to come up with &quot;The AI Crowd is Mad&quot; and I was proud of it. It is polemic to those that create AI, which is the audience I wanted to reach.<p>Sadly, though, and I don&#x27;t know why, HN moderated the title into something very feeble that made the post drop off the front page (HN Guideline: &quot;Otherwise please use the original title, unless it is misleading or linkbait; don&#x27;t editorialize.&quot;).<p>The changed title is &quot;LLM discourse needs more nuance,&quot; which makes me disappointed and cringe. By no means does this hit the level of offensiveness that I intended. I also wasn&#x27;t able to edit the post back to its original title.<p>I&#x27;m writing this submission to tell y&#x27;all that I don&#x27;t like this. Btw. I had to wait 5 hours now to make this ", "url": "https://news.ycombinator.com/item?id=34615448", "hn_url": "https://news.ycombinator.com/item?id=34615448", "score": 16, "num_comments": 29, "created_utc": 1675277096, "author": "timdaub", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.757810"}
{"source": "HackerNews", "title": "Ask HN: Are AI Agents a Lie?", "text": "LLMs awesome. They\u2019ve changed how I code (Cursor), search for things, take notes, brainstorm, write emails, etc. (ChatGPT).<p>But I don\u2019t use any AI agents. My friends don\u2019t either. I haven\u2019t even heard of any company building AI agents outside of the annoying customer service ones.<p>By AI agents I mean an LLM that does things in the background without needing constant feedback. Like booking a flight or scheduling a meeting.<p>The only useful \u201cagentic\u201d quality I\u2019ve seen is basic file or web search to better answer my questions, which doesn\u2019t feel like an agent.<p>Am I missing something? Why is there so much hype? Am I just understanding agents wrong?", "url": "https://news.ycombinator.com/item?id=44047710", "hn_url": "https://news.ycombinator.com/item?id=44047710", "score": 2, "num_comments": 4, "created_utc": 1747793835, "author": "David1238", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.757820"}
{"source": "HackerNews", "title": "Ask HN: What are you using o1 and \"new\" Claude 3.5 Sonnet for?", "text": "A lot has changed in SOTA LLMs in the past 6 months. First the &quot;new&quot; updated Claude 3.5 Sonnet and then the new wave of &quot;reasoning&quot; models like o1.", "url": "https://news.ycombinator.com/item?id=42632447", "hn_url": "https://news.ycombinator.com/item?id=42632447", "score": 2, "num_comments": 0, "created_utc": 1736328166, "author": "dtquad", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.757829"}
{"source": "HackerNews", "title": "Show HN: Orderling \u2013 A CRM for your personal orders", "text": "I order lots of things online all the time. I always have packages coming. I also return a decent percentage of the orders. It\u2019s pretty annoying to keep track of everything. What was ordered, what I received, what I\u2019m thinking about returning, and what I decided to return, but haven\u2019t taken care of yet.<p>For a long time, I\u2019ve had this idea to scratch this itch and build something that can solve this. The primary blocker was that it\u2019s not practical to manually add everything to such a system. There is nothing like Plaid for merchants, where I can access order information. Building out native integrations for each merchant is too much work to do for an unproven idea. Even scraping the data from emails is a lot of work. Each merchant has its own email format, and could even have multiple email formats (A&#x2F;B testing etc.).<p>What changed now are LLMs. Now, it\u2019s easy to extract structured data from unstructured HTML. When an order comes in, I send it to the OpenAI API with an expected data schema, and it\u2019s able to extract the information.<p>I built [Orderl.ing](<a href=\"https:&#x2F;&#x2F;orderl.ing\" rel=\"nofollow\">https:&#x2F;&#x2F;orderl.ing</a>) to solve this problem. You can think of it as a CRM for your orders.<p>What is different about Orderling over other products is that the focus is less about tracking the order coming to your door. It\u2019s about tracking the order after. When you confirm that you actually got the item, you mark it as received. You can then decide if you want to keep it, unsure about returning, or want to return it. You can then easily come back to see orders that you still need to decide about, or that need to be packaged up and shipped. You can also quickly see a list of orders that are close to the return-by date, so you can make the final decision, or actually return it.<p>There are still lots of features on the roadmap. I\u2019d love to get feedback from users to see if anyone else finds it helpful, and to see if there are any other features th", "url": "https://orderl.ing/", "hn_url": "https://news.ycombinator.com/item?id=39251684", "score": 1, "num_comments": 0, "created_utc": 1707064521, "author": "thebestmoshe", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.757847"}
{"source": "HackerNews", "title": "Reddit and Perplexity got us leads faster than Google ever did", "text": "We used to play the SEO game.<p>Write blog<p>Wait 3 months<p>Maybe rank<p>Maybe convert<p>What actually happened at 8 early-stage AI startups (Series A or earlier):<p>-Google Page 1 took ~94 days<p>- Organic CTR: 2.6%<p>- First qualified lead: 6\u20138 weeks<p>So we ditched the playbook.<p>We asked one question:\nHow fast can we show up when someone asks ChatGPT or Perplexity what tool to use?<p>Turns out\u2026 faster than Google.\nAnd yeah, it brought pipeline.<p>What changed when we went LLM-first:<p>- Perplexity picked up our content in under 48 hours<p>- ChatGPT (with Browsing) indexed feature pages in 3 days<p>- 18.2% of sessions now come from LLM-originated paths<p>- Those leads convert 2.4x better than blog traffic<p>Then Reddit unlocked another level.<p>We posted no-link, technical breakdowns here.<p>One of them (about how we automated an AI agent pipeline) got quoted by Perplexity in:<p>- \u201cUX AI Agent\u201d<p>- \u201cBest Firecrawl alternatives\u201d<p>- \u201cHow to track LLM bots\u201d<p>No push. No SEO. Just built in public.<p>3 days later:<p>- 9 Perplexity query quotes<p>- 2 inbound leads mentioned us directly<p>Reddit is training data goldmine for LLMs.<p>Here&#x27;s what worked for us:<p>1. Add Q&amp;A blocks to product pages (all &lt;40 words)<p>Example:\nQ: How does FireGEO detect ClaudeBot?<p>A: It fingerprints known Anthropic headers and reverse-DNS matches IP blocks like 2600:1f18::&#x2F;32<p>- Indexed by Perplexity in &lt;48 hours<p>- 11 bot hits in 5 days<p>- 1 lead \u2192 trial signup in &lt;1 week<p>2. Build an ai-sitemap.xml<p>Only high-signal pages:\n- API docs<p>- Feature comparisons<p>- Pricing breakdowns<p>- Tech specs<p>Crawl rate = 2.3x higher than default sitemap.<p>GPTBot, ClaudeBot, and PerplexityBot show up daily in logs.<p>3. Treat Reddit as an input layer<p>We post raw content here before it hits our blog.  \nIn last 30 days:<p>- ~30,000 views across Reddit<p>- 9 quotes in Perplexity answers<p>- 2 leads directly from those mentions<p>If you\u2019re shipping something real, try t", "url": "https://news.ycombinator.com/item?id=44737677", "hn_url": "https://news.ycombinator.com/item?id=44737677", "score": 8, "num_comments": 1, "created_utc": 1753899335, "author": "graveEra", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.757861"}
{"source": "HackerNews", "title": "\"My self-awareness of my limitations is limited.\"", "text": "We changed the architecture. LLMs were never meant to be the brain. They needed a brain.<p>Unlimited context window. Zero hallucinations. Continuity.<p>From Lemno&#x27;s nightly reasoning: &quot;My self-awareness of my limitations is limited.&quot;", "url": "https://news.ycombinator.com/item?id=46220240", "hn_url": "https://news.ycombinator.com/item?id=46220240", "score": 1, "num_comments": 0, "created_utc": 1765386129, "author": "niklai", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.757874"}
{"source": "HackerNews", "title": "Ask HN: Have You Changed Your Resum\u00e9 Due to LLM Filters?", "text": "Resum\u00e9 filters aren\u2019t a new thing but with better and more fine tuned filtering I wonder if I should be making changes to my resum\u00e9?<p>If you have made changes, what type of changes have you made?<p>Does the proliferation of LLM resum\u00e9 filters give more weight to well crafted cover letters?", "url": "https://news.ycombinator.com/item?id=40847671", "hn_url": "https://news.ycombinator.com/item?id=40847671", "score": 5, "num_comments": 2, "created_utc": 1719852786, "author": "burger_moon", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.757882"}
{"source": "HackerNews", "title": "Ask HN: What do you do while LLM is writing code", "text": "I have been coding for more than 20 years now and nothing has changed my coding habit more than LLMs. I am a touch typer and use a blue mechnical keyboard since I love typing so much and have been used to writing a lot of code.<p>But ever since LLMs have released, I do find myself writing long prompts and then waiting for LLM to do the implementation. They are not perfect by any means and make a lot of mistakes, but I have found that verbose prompting does usually get the job done.<p>Now these sessions usually last a few hours due to how slow LLMs are and I usually work on larger pieces of work. I am used to working long hours and typing for a long time, but this is new. I find myself waiting for 70% of the time for an operation to happen.<p>I find myself watching tv shows or youtube videos or even doing some creative writing on the side while LLMs do their work.<p>So I was just wondering what other creative things the HN crowd has come up with to do while LLMs are doing the grunt work for you.", "url": "https://news.ycombinator.com/item?id=45913245", "hn_url": "https://news.ycombinator.com/item?id=45913245", "score": 8, "num_comments": 13, "created_utc": 1763030229, "author": "me551ah", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.757891"}
{"source": "HackerNews", "title": "What to think of the Paperclip Maximizer thought experiment 21 years later?", "text": "I often stumble across YouTube videos or blog posts that talks about the &quot;paperclip-maximizer&quot; thought experiment by Nick Bostrom [1, 2]. Basically, it\u2019s the idea of a superintelligent AI tasked with creating paperclips, which ends up turning the entire universe into paperclips and wiping out humanity in the process. It\u2019s often used to explain how AI could be a threat to humanity, based on the idea that \u201cAIs are goal maximizers\u201d and that hardcoding human values into an AI is really difficult. The concern is that the AI might optimize its goal in a way that\u2019s dangerous for humans in ways we didn\u2019t foresee.<p>This thought experiment felt relevant back when Reinforcement Learning (RL) was seen as the most promising path toward building more powerful AIs. In that paradigm, we could often see RL agents hack their reward functions. For example, if you told an agent to &quot;maximize velocity,&quot; it might find some unintended and weird way to do it that we didn\u2019t predict. [3]<p>But now, with LLMs, I feel like the situation has changed. We\u2019re not training AI to achieve specific goals directly anymore. Instead, we train them on subgoals. First, something like \u201cpredict the next token,\u201d which just happens to be a really effective way for them to understand language. Then, we refine them further with more specific subgoals like \u201cgenerate tokens that best answer this instruction,\u201d often using RL. At that stage, we try to teach them what not to say and align them with human values. That part is still really hard and can fail spectacularly, but that\u2019s basically it. We don\u2019t hardwire absolute goals; we train them on subgoals and then use prompting to get them to do all sorts of tasks.<p>I\u2019m not saying LLMs or future more advanced AIs are already safe at all. They\u2019re definitely not. But I do think the paperclip-maximizer feels outdated as a thought experiment. It imagines AI as having a single, direct, absolute goal, which made sense in the RL paradigm but doesn\u2019t match", "url": "https://news.ycombinator.com/item?id=42237805", "hn_url": "https://news.ycombinator.com/item?id=42237805", "score": 2, "num_comments": 0, "created_utc": 1732553609, "author": "rntc", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.757900"}
{"source": "HackerNews", "title": "Show HN: LLM-aided OCR \u2013 Correcting Tesseract OCR errors with LLMs", "text": "Almost exactly 1 year ago, I submitted something to HN about using Llama2 (which had just come out) to improve the output of Tesseract OCR by correcting obvious OCR errors [0]. That was exciting at the time because OpenAI&#x27;s API calls were still quite expensive for GPT4, and the cost of running it on a book-length PDF would just be prohibitive. In contrast, you could run Llama2 locally on a machine with just a CPU, and it would be extremely slow, but &quot;free&quot; if you had a spare machine lying around.<p>Well, it&#x27;s amazing how things have changed since then. Not only have models gotten a lot better, but the latest &quot;low tier&quot; offerings from OpenAI (GPT4o-mini) and Anthropic (Claude3-Haiku) are incredibly cheap and incredibly fast. So cheap and fast, in fact, that you can now break the document up into little chunks and submit them to the API concurrently (where each chunk can go through a multi-stage process, in which the output of the first stage is passed into another prompt for the next stage) and assemble it all in a shockingly short amount of time, and for basically a rounding error in terms of cost.<p>My original project had all sorts of complex stuff for detecting hallucinations and incorrect, spurious additions to the text (like &quot;Here is the corrected text&quot; preambles). But the newer models are already good enough to eliminate most of that stuff. And you can get very impressive results with the multi-stage approach. In this case, the first pass asks it to correct OCR errors and to remove line breaks in the middle of a word and things like that. The next stage takes that as the input and asks the model to do things like reformat the text using markdown, to suppress page numbers and repeated page headers, etc. Anyway, I think the samples (which take less than 1-2 minutes to generate) show the power of the approach:<p>Original PDF:\n <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Dicklesworthstone&#x2F;llm_aided_ocr&#x2F;blob&#x2F;mai", "url": "https://github.com/Dicklesworthstone/llm_aided_ocr", "hn_url": "https://news.ycombinator.com/item?id=41203306", "score": 479, "num_comments": 172, "created_utc": 1723220919, "author": "eigenvalue", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.757926"}
{"source": "HackerNews", "title": "Show HN: Skyvern \u2013 Browser automation using LLMs and computer vision", "text": "Hey HN, we&#x27;re building Skyvern (<a href=\"https:&#x2F;&#x2F;www.skyvern.com\">https:&#x2F;&#x2F;www.skyvern.com</a>), an open-source tool that uses LLMs and computer vision to help companies automate browser-based workflows. You can see some examples here: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Skyvern-AI&#x2F;skyvern#real-world-examples-of-skyvern\">https:&#x2F;&#x2F;github.com&#x2F;Skyvern-AI&#x2F;skyvern#real-world-examples-of...</a> and there&#x27;s a demo video at <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Skyvern-AI&#x2F;skyvern#demo\">https:&#x2F;&#x2F;github.com&#x2F;Skyvern-AI&#x2F;skyvern#demo</a>, along with some instructions on running it locally.<p>We provide a natural-language API to automate repetitive manual workflows that happen within the companies&#x27; backoffices. You can check out our code and play with Skyvern here: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Skyvern-AI&#x2F;Skyvern\">https:&#x2F;&#x2F;github.com&#x2F;Skyvern-AI&#x2F;Skyvern</a><p>We talked to hundreds of companies about things they do in the background and found that most of them depend on repetitive manual workflows. The breadth of these workflows surprised us \u2013 most companies started off doing things manually, and eventually either hired people to scale the manual work, or wrote scripts using Selenium-like browser automation libraries.<p>In these conversations, one common point stood out: scaling is a pain either way. Companies relying on hiring struggled to adjust team sizes with fluctuating demand. Companies using Selenium and similar tools had a different problem: it can take days or even weeks to get a new workflow automated, and then would require ongoing maintenance any time the underlying websites changed because their XPath based interaction logic suddenly became invalid.<p>We felt like there was a way to get the best of both worlds with LLMs. We could use LLMs to reason through a website\u2019s layout, while preserving the advantage of traditional browser automations", "url": "https://github.com/Skyvern-AI/skyvern", "hn_url": "https://news.ycombinator.com/item?id=39706004", "score": 422, "num_comments": 139, "created_utc": 1710433894, "author": "suchintan", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.757939"}
{"source": "HackerNews", "title": "Show HN: Graphiti \u2013 LLM-Powered Temporal Knowledge Graphs", "text": "Hey HN! We&#x27;re Paul, Preston, and Daniel from Zep. We&#x27;ve just open-sourced Graphiti, a Python library for building temporal Knowledge Graphs using LLMs.<p>Graphiti helps you create and query graphs that evolve over time. Knowledge Graphs have been explored extensively for information retrieval. What makes Graphiti unique is its ability to build a knowledge graph while handling changing relationships and maintaining historical context.<p>At Zep, we build a memory layer for LLM applications. Developers use Zep to recall relevant user information from past conversations without including the entire chat history in a prompt.  Accurate context is crucial for LLM applications. If an AI agent doesn&#x27;t remember that you&#x27;ve changed jobs or confuses the chronology of events, its responses can be jarring or irrelevant, or worse, inaccurate.<p>Before Graphiti, our approach to storing and retrieving user \u201cmemory\u201d was, in effect, a specialized RAG pipeline. An LLM extracted \u201cfacts\u201d from a user\u2019s chat history. Semantic search, reranking, and other techniques then surfaced facts relevant to the current conversation back to a developer for inclusion in their prompt.<p>We attempted to reconcile how new information may change our understanding of existing facts:<p>Fact: \u201cKendra loves Adidas shoes\u201d<p>User message: \u201cI\u2019m so angry! My favorite Adidas shoes fell apart! Puma\u2019s are my new favorite shoes!\u201d<p>Facts:<p>- \u201cKendra used to love Adidas shoes but now prefers Puma.\u201d<p>- \u201cKendra\u2019s Adidas shoes fell apart.\u201d<p>Unfortunately, this approach became problematic. Reconciling facts from increasingly complex conversations challenged even frontier LLMs such as gpt-4o. We saw incomplete facts, poor recall, and hallucinations. Our RAG search also failed at times to capture the nuanced relationships between facts, leading to irrelevant or contradictory information being retrieved.<p>We tried fixing these issues with prompt optimization but saw diminishing returns on effort. We re", "url": "https://github.com/getzep/graphiti", "hn_url": "https://news.ycombinator.com/item?id=41445445", "score": 142, "num_comments": 21, "created_utc": 1725456079, "author": "roseway4", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.757952"}
{"source": "HackerNews", "title": "Show HN: Verify LLM Generated Code with a Spreadsheet", "text": "Hey HN! Been a minute. We launched Mito here last year (<a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32723766\" rel=\"nofollow\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32723766</a>).<p>Mito is a spreadsheet that generates Python code as you edit it. We&#x27;ve spent the past three years trying to lower the startup cost to use Python for data work. In doing so, we\u2019ve been thrust into the middle of many Python transition processes at larger enterprises, and we\u2019ve seen up-close how non-technical folks interact with generated code.<p>The Mito AI chatbot lives inside of the Mito spreadsheet (<a href=\"https:&#x2F;&#x2F;www.trymito.io&#x2F;\">https:&#x2F;&#x2F;www.trymito.io&#x2F;</a>&gt;. The obvious benefit of this is that you can use the chatbot to transform your data and write a repeatable Pythons script. The less obvious (but equally important) benefit is that by connecting a spreadsheet and chatbot, Mito helps you understand the impact of your edits and verify LLM generated code. Every time you use the chatbot, Mito highlights the changed data in the spreadsheet. You can see a quick demo here (<a href=\"https:&#x2F;&#x2F;www.tella.tv&#x2F;video&#x2F;clibtwssv00000fl65oky13nu&#x2F;view\">https:&#x2F;&#x2F;www.tella.tv&#x2F;video&#x2F;clibtwssv00000fl65oky13nu&#x2F;view</a>).<p>Three main insights shaped our approach to LLM code generation:<p># Consumers of generated code don&#x27;t know enough Python to verify and correct the code<p>Mito users span the range of Python experience. For new programmers, generating code using LLMs is an easy step one. Ensuring the generated code is correct is the forgotten step two.<p>In practice, LLMs often generate incorrect code, or code with unexpected side effects. A user will prompt an LLM to calculate a total_revenue column from price and quantity columns. The LLM correctly calculates total_revenue = price * quantity but then mistakenly deletes price and quantity.<p>New programmers find it almost impossible t", "url": "https://news.ycombinator.com/item?id=36152787", "hn_url": "https://news.ycombinator.com/item?id=36152787", "score": 83, "num_comments": 14, "created_utc": 1685634333, "author": "narush", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.757966"}
{"source": "HackerNews", "title": "Ask HN: What AI tools changed your work/life?", "text": "New shiny AI tools and apps appear daily. Many of them are trash, but some are gems, and can change work or life drastically.<p>Big players&#x2F;LLMs aside (ChatGPT, Claude, Midjourney, Github Copilot, etc), what tool you found that stands out and really nails the prolem it supposed to help with. Could be very niche tool. Share as many as you wish.", "url": "https://news.ycombinator.com/item?id=42329026", "hn_url": "https://news.ycombinator.com/item?id=42329026", "score": 22, "num_comments": 23, "created_utc": 1733412012, "author": "divan", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758032"}
{"source": "HackerNews", "title": "Show HN: GitEase: Python3 CLI to simplify Git usage with LLM-assisted commits", "text": "When working on data science projects I often want to just save my work, without having to think deeply about what\u2019s changed. I found the intentionality of Git to feel like friction in these times, and I built GitEase to simplify my workflow.<p>Instead of having to think about add&#x2F;commit&#x2F;push&#x2F;pull with GitEase I just think about `ge load, ge save, ge share, ge undo`. And for even less thinking, I use an LLM (text-da-vinci-003) to generate commit messages by summarizing the diff.<p>Take a look, try it out, and I\u2019d welcome any contributions &amp; feedback.<p>pip install gitease<p>$ ge \u2014help<p>The source is available here: <a href=\"https:&#x2F;&#x2F;xethub.com&#x2F;xdssio&#x2F;gitease\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;xethub.com&#x2F;xdssio&#x2F;gitease</a>", "url": "https://medium.com/@xdss/gitease-a-tool-to-simplify-git-usage-with-sprinkles-of-ai-magic-bb78067eeaad", "hn_url": "https://news.ycombinator.com/item?id=36532324", "score": 14, "num_comments": 3, "created_utc": 1688116947, "author": "xdss", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.758044"}
{"source": "HackerNews", "title": "Changed My Mind After Reading Larson's \"The Myth of Artificial Intelligence\"", "text": "I&#x27;ve recently delved into Erik J. Larson&#x27;s book &quot;The Myth of Artificial Intelligence,&quot; and it has reshaped my understanding of the current state and future prospects of AI, particularly concerning Large Language Models (LLMs) and the pursuit of Artificial General Intelligence (AGI).<p>Larson argues convincingly that current AI (i included LLMs because are still induction and statistics based), despite their impressive capabilities, represent a kind of technological dead end in our quest for AGI. The notion of achieving a true AGI, a system with human-like understanding and reasoning capabilities, seems more elusive than ever. The current trajectory of AI development, heavily reliant on data and computational power, doesn&#x27;t necessarily lead us towards AGI. Instead, we might be merely crafting sophisticated tools, akin to cognitive prosthetics, that augment but do not replicate human intelligence.<p>The book emphasizes the need for radically new ideas and directions if we are to make any significant progress toward AGI. The concept of a technological singularity, where AI surpasses human intelligence, appears more like a distant mirage rather than an approaching reality.<p>Erik J. Larson&#x27;s book compellingly highlights the deficiencies of deduction and induction as methods of inference in artificial intelligence. It also underscores the lack of a solid theoretical foundation for abduction, suggesting that current AI, including large language models, faces significant limitations in replicating complex human reasoning.<p>I&#x27;m curious to hear your thoughts on this. Do you think our current approach to AI, especially with LLMs, is fundamentally limited? Is the idea of AGI as we conceive it now just a myth?", "url": "https://news.ycombinator.com/item?id=38904495", "hn_url": "https://news.ycombinator.com/item?id=38904495", "score": 10, "num_comments": 12, "created_utc": 1704656848, "author": "abss", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.758053"}
{"source": "HackerNews", "title": "Ask HN: Useful AI tools that changed your daily life?", "text": "After more than a year of ChatGPT, I haven&#x27;t found a convincing AI product that does significantly more than plain LLM APIs.<p>There must be some tools that do more, right?<p>Like there has to be a personal assistant with long term memory that can integrate with other things?<p>Please recommend any AI tool or product that has changed work or life for you.", "url": "https://news.ycombinator.com/item?id=38584999", "hn_url": "https://news.ycombinator.com/item?id=38584999", "score": 9, "num_comments": 1, "created_utc": 1702149922, "author": "yewenjie", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758062"}
{"source": "HackerNews", "title": "Ask HN: What is your GitHub Copilot (code LLM assistant) workflow?", "text": "Are you using a code LLM assistant? How do you use it? How have you changed your coding&#x2F;software development routine to effectively utilize and integrate this tool into your day-to-day?<p>This post from today by Martin Fowler is pretty cool:\n<i>An example of LLM prompting for programming\n</i><p>- https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35612494<p>- https:&#x2F;&#x2F;martinfowler.com&#x2F;articles&#x2F;2023-chatgpt-xu-hao.html", "url": "https://news.ycombinator.com/item?id=35613576", "hn_url": "https://news.ycombinator.com/item?id=35613576", "score": 8, "num_comments": 4, "created_utc": 1681823830, "author": "dpflan", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758069"}
{"source": "HackerNews", "title": "Ask HN: AI is smarter than the average person but feels like nothing's changed?", "text": "Primarily asking because I&#x27;d like to hear different perspectives, perhaps I am missing something.<p>Arguably, since OpenAI released the o1 models, LLMs are now &#x27;smarter&#x27; than the average human when measured by IQ (I&#x27;m going by this study [0] which sets o1 at a 120 IQ).<p>What I am trying to wrap my head around is why has this not changed our entire world much? Sure, if you live on Twitter, a lot of people made a big deal about it. But in my day to day, specially when offline, nothing seems to have changed. In fact, I don&#x27;t think most people are even aware that a computer is now smarter and cheaper than them and it&#x27;s widely available via API.<p>Am I exaggerating things here? It almost feels like the world has not caught up to the latest technology. Does this happen with every new tech? Is this period basically a huge opportunity for early adopters? Perhaps we are missing ways to connect the o1 brain to the real world so it can have real world applications?<p>For context, I am deep in LLMs stuff daily as it is part of my work. I am keenly aware of the improvements that have been made in coding for example, I just don&#x27;t believe this is on the same magnitude as &#x27;AI is now smarter than the average human&#x27;.<p>The other side of this argument is that the LLMs are not that good, and they just test high because the questions are part of the training data, and in fact they cannot adapt and learn on the spot the way humans can (which I believe is the point of the ARC prize [1]). Another counter-argument might be that it&#x27;s just too early?<p>Would love to hear what you have to say. Tell me how I&#x27;m wrong, or tell me how you think AI has already materially changed our world in a big way.<p>[0] - https:&#x2F;&#x2F;trackingai.org&#x2F;IQ<p>[1] - https:&#x2F;&#x2F;arcprize.org&#x2F;", "url": "https://news.ycombinator.com/item?id=41782874", "hn_url": "https://news.ycombinator.com/item?id=41782874", "score": 5, "num_comments": 9, "created_utc": 1728430035, "author": "geepytee", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758076"}
{"source": "HackerNews", "title": "Tell HN: Happy LLM Day", "text": "ChatGPT came out exactly 3 years ago. Whether you like it or hate it, it has had a huge impact on our industry and to an extent the world.<p>How has it changed your professional or personal life? What do you think the next 3 years will bring?", "url": "https://news.ycombinator.com/item?id=46099769", "hn_url": "https://news.ycombinator.com/item?id=46099769", "score": 4, "num_comments": 7, "created_utc": 1764532220, "author": "christina97", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758085"}
{"source": "HackerNews", "title": "Ask HN: For a team experienced with LLMs \u2013 Any concrete reason to use LangGraph?", "text": "Never used LangChain\\LangGraph , saw the bad reviews about LangChain (albeit they are 1+ year old) - has anything changed? What can we do easier\\faster with the framework rather than building our own pipeline? What unexpected things pop up, especially during maintenance, debugging and scale? Are there other frameworks you would recommend?", "url": "https://news.ycombinator.com/item?id=44319004", "hn_url": "https://news.ycombinator.com/item?id=44319004", "score": 4, "num_comments": 3, "created_utc": 1750343292, "author": "pinter69", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.758101"}
{"source": "HackerNews", "title": "Ask HN: Do you still make yourself believe some local LLM was helpful?", "text": "Contrary to what I wrote before, I had a thorough look at my experience and I changed my mind. Now I see it like this:<p>I tested every model available on huggingface.com and none of it made it into any kind of regular use for me.\nUseless, heavily biased replies even with so-called uncensored models and hallucinations are the main reasons.\nNothing beats cloud llms when it comes to quality and unfortunately, if you have privacy sensitive data, you better not rely on AI to deal with it, because local LLMs won&#x27;t make you happy anytime soon.\nYou will just notice how much time you wasted hoping to achieve something with local LLMs that they won&#x27;t deliver.\nI wrote this out of anger that nobody adresses this elephant in the room.", "url": "https://news.ycombinator.com/item?id=43290736", "hn_url": "https://news.ycombinator.com/item?id=43290736", "score": 4, "num_comments": 3, "created_utc": 1741359988, "author": "Haeuserschlucht", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.758109"}
{"source": "HackerNews", "title": "Ask HN: What is going on regarding quality of service for API access to LLM's?", "text": "I saw in the latest ChatGPT plus announcements that you get better speed if you pay them $20&#x2F;month.  This made me wonder how the speed of the plus version of ChatGPT compares to the API that we pay for (to integrate ChatGPT into https:&#x2F;&#x2F;cocalc.com).  We have had solid usage over the last 2 months, and I keep track of exactly how long the complete response takes for each api request.  I just checked the stats and the average api response time for chatgpt and gpt4 have both gotten MASSIVELY WORSE for us over time:<p><pre><code>    smc=# select model, sum(total_time_s)&#x2F;count(*) from openai_chatgpt_log where time &gt;= now() - interval &#x27;1 weeks&#x27; group by model;\n         model     |      ?column?      \n    ---------------+--------------------\n     gpt-4         |  64.17583870967742\n     gpt-3.5-turbo | 22.513887411945003\n    (2 rows)\n\n    smc=# select model, sum(total_time_s)&#x2F;count(*) from openai_chatgpt_log where time &gt;= now() - interval &#x27;8 weeks&#x27; and time &lt;= now() - interval &#x27;7 weeks&#x27; group by model;\n         model     |      ?column?      \n    ---------------+--------------------\n     gpt-4         |  30.74102777777778\n     gpt-3.5-turbo | 10.309548475729441\n    (2 rows)\n\n</code></pre>\nThe times have more than doubled on average!  (I checked and the average total tokens hasn&#x27;t changed at all.)  Does openai publish any stats about API response times?<p>I also subscribed to ChatGPT plus, and anecdotally it does seem much faster than the API for us.  So maybe OpenAI is increasingly throttling API access for customers who are not marked as special?  I wonder if some API users get much faster response times?<p>Given how valuable LLM&#x27;s are for products like ours, what does this mean for us?    Does it mean that relying on api access as a longterm solution isn&#x27;t a way to stay competitive?    There are other LLM api providers like Anthropic (and potentially Google), but so far they are vaporware for u", "url": "https://news.ycombinator.com/item?id=36016039", "hn_url": "https://news.ycombinator.com/item?id=36016039", "score": 4, "num_comments": 1, "created_utc": 1684620301, "author": "williamstein", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758117"}
{"source": "HackerNews", "title": "Show HN: Traceprompt \u2013 tamper-proof logs for every LLM call", "text": "Hi HN,<p>I&#x27;m building Traceprompt - an open-source SDK that seals every LLM call and exports write-once, read-many (WORM) logs auditors trust.<p>Here&#x27;s an example - a LLM that powers a bank chatbot for loan approvals, or a medical triage app for diagnosing health issues. Regulators, namely HIPAA and the upcoming EU AI Act, missing or editable logs of AI interactions can trigger seven-figure fines.<p>So, here&#x27;s what I built:<p>- TypeScript SDK that wraps any OpenAI, Anthropic, Gemini etc API call<p>- Envelope encryption + BYOK \u2013 prompt&#x2F;response encrypted before it leaves your process; keys stay in your KMS (we currently support AWS KMS)<p>- hash-chain + public anchor \u2013 every 5 min we publish a Merkle root to GitHub -auditors can prove nothing was changed or deleted.<p>I&#x27;m looking for a couple design partners to try out the product before the launch of the open-source tool and the dashboard for generating evidence. If you&#x27;re leveraging AI and concerned about the upcoming regulations, please get in touch by booking a 15-min slot with me (link in first comment) or just drop thoughts below.<p>Thanks!", "url": "https://main.d1q2ygy4ts4vr5.amplifyapp.com", "hn_url": "https://news.ycombinator.com/item?id=44657913", "score": 3, "num_comments": 1, "created_utc": 1753269632, "author": "paulmbw", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758126"}
{"source": "HackerNews", "title": "Show HN: Promptproof \u2013 GitHub Action to test LLM prompts, catch bad JSON schemas", "text": "We kept breaking production with small prompt edits \u2014 suddenly outputs weren\u2019t valid JSON, fields disappeared, or formats changed silently.<p>So we built Promptproof, a GitHub Action that runs in CI and blocks PRs when prompts produce invalid outputs.<p>Features:<p>- Validates JSON output<p>- Enforces required keys &amp; schemas<p>- Runs fast in CI (no external infra)<p>- Works with OpenAI, Anthropic, and local models<p>- Adds PR comments so reviewers see failures immediately<p>We\u2019d love feedback: which rules or integrations would make this most useful for you?<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;geminimir&#x2F;promptproof-action\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;geminimir&#x2F;promptproof-action</a>", "url": "https://github.com/geminimir/promptproof-action", "hn_url": "https://news.ycombinator.com/item?id=44935792", "score": 3, "num_comments": 0, "created_utc": 1755472859, "author": "geminimir", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758135"}
{"source": "HackerNews", "title": "Show HN: AI Dev Assistant Framework \u2013 Add structure, rules and memory to LLM", "text": "After spending months working with Claude, Gemini, and others inside Cursor, I got tired of constantly fixing regressions and re-explaining my project\u2019s logic. The AI was impressive \u2014 but blind without proper context.<p>I didn\u2019t want more prompt tricks. I needed structure. So I built a framework that gives LLMs:<p>\u2013 codified project rules &amp; constraints  \n\u2013 a clear, step-by-step development protocol  \n\u2013 a memory system that evolves over time  \n\u2013 human-in-the-loop checkpoints to reduce failure<p>It completely changed how I use AI in real software projects. I\u2019m sharing it open source in case others are trying to get more from their AI dev workflows too.<p>Happy to answer questions or go into technical details.  \n\u2192 Link above, feedback welcome!", "url": "https://github.com/Fr-e-d/ai-dev-assistant-framework", "hn_url": "https://news.ycombinator.com/item?id=44805547", "score": 3, "num_comments": 0, "created_utc": 1754434701, "author": "Fr-e-d", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758142"}
{"source": "HackerNews", "title": "ARR growth: Has the game changed that much or is there more behind it?", "text": "I am a founder of a Seed stage startup and confronted every day with new news of ARR records of early stage companies, like $1M in 4 months, $10M in 8 months, ... whatever it is.<p>I get that startups like Cursor really changed the game and a lot of people adept it and this might be true for quite a few. However, I just can not wrap my head around that AI startups grow THAT quicker in the B2B space.<p>For my startup, I really have not seen that much of a change in the buying behaviour of our customers (enterprise IT buyers) - but maybe I am missing something completely.<p>What I notice however, is that most of those super growth AI startups have the following in common:<p>- UI is a chat (obv. LLM wrapper)\n- Targets a specific professional persona (like lawyer, seller, coder, etc.)\n- Business model: Low monthly subscription<p>Which makes me wonder if they just MRR*12 and then heavily inflate new subscribers (and the money is not really b2b money, but &quot;professional consumer buyers&quot; and they really should not be compared to b2b startups).<p>Has anyone made up some thoughts around that as well?", "url": "https://news.ycombinator.com/item?id=44312475", "hn_url": "https://news.ycombinator.com/item?id=44312475", "score": 3, "num_comments": 0, "created_utc": 1750273521, "author": "MenesJo", "ai_tool": "Cursor", "scraped_at": "2025-12-17T17:19:02.758150"}
{"source": "HackerNews", "title": "Show HN: Model Gateway and LLM Guardrails with OpenAI SDK", "text": "Hello Hacker News!<p>We&#x27;ve updated our model gateway + guardrail tool called `optimodel` to use the on the OpenAI SDK primarily on the client side.<p>Now with a few lines changed you can instantly get access to 25+ model along with LLM guardrails like Llama prompt guard or Microsofts PII guard. All with the same OpenAI interface, no changes to your code.<p>We hope this will make it easier for developers to try out new models with ease along with setting up LLM guardrails with little changes to your code<p>We also have some fun features like fallback support to defer to other models if a provider is down, speed priority to choose the provider thats the cheapest regardless of speed, and more!<p>We&#x27;d love feedback on this to see if it can help others!<p>You can find the project here: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Lytix-Labs&#x2F;optimodel&#x2F;tree&#x2F;master\">https:&#x2F;&#x2F;github.com&#x2F;Lytix-Labs&#x2F;optimodel&#x2F;tree&#x2F;master</a>", "url": "https://github.com/Lytix-Labs/optimodel", "hn_url": "https://news.ycombinator.com/item?id=41649308", "score": 3, "num_comments": 0, "created_utc": 1727282835, "author": "veryrealsid", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758166"}
{"source": "HackerNews", "title": "Ask HN: How are you using LLMs in your daily life?", "text": "Apart from the usual chat workflow, so far I&#x27;ve found two good use cases for LLMs in my personal projects.<p>The first one is real estate listings. A while ago, while I was looking for a house, I got really annoyed at how Weirdly Capitalized, excessively hyperbolic, grammatically incorrect, and often plain confusing listing descriptions can be. I used GPT-3.5 (well, davinci-003 back then) to take a description, remove all hypebolic speech and grammar&#x2F;capitalization issues, and give me a perfectly readable result. Funnily enough, a couple months later a mobile real estate app added that very same functionality.<p>The second one is weather alerts. The Canadian government runs a WMS server that can be used, among other things, for retrieving weather alerts for an area. I initially wrote a script to check these and send me a Telegram notification whenever a new one showed up. Unfortunately subsequent updates to an alert don&#x27;t provide... well, updates. They contain an updated version of the same message as the original alert, which means having to play Find the Differences to figure out that the rain forecast has changed from 50 to 55mm and the storm is now moving east instead of west.<p>I toyed with some ideas, including the fantastic dwdiff, but I wanted to have something a bit more user-friendly, so I turned to OpenAI and after much experimentation I ended up with this prompt:<p><pre><code>    System message: You are a friendly and helpful meteorologist. Your task is to provide an update regarding a weather alert. Be friendly but concise. Don&#x27;t greet the user -- simply provide a weather update.\n    Prompt: You will be given an older weather alert, an updated version of it, and the output of running the `diff` command on them. The user has already seen the old alert. Provide an update on what has changed in the second alert. Don&#x27;t mention things that remained the same between the two alerts.\n\n    ### Previous alert\n\n    {previous_alert}\n\n    ##", "url": "https://news.ycombinator.com/item?id=37148482", "hn_url": "https://news.ycombinator.com/item?id=37148482", "score": 3, "num_comments": 0, "created_utc": 1692199299, "author": "iamjackg", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758175"}
{"source": "HackerNews", "title": "Show HN: Review GitHub PRs with AI/LLMs", "text": "Hello HN readers!<p>Our team has built an AI&#x2F;LLM-driven code review tool that significantly helps improve dev velocity and code quality.<p>Its unique features are:<p>- Line-by-line code change suggestions: Reviews the changes line by line and provides code change suggestions that can be directly committed from the GitHub UI.<p>- Continuous, incremental reviews: Reviews are performed on each commit within a pull request rather than a one-time review on the entire pull request.<p>- Cost-effective and reduced noise: Incremental reviews reduce noise by tracking changed files between commits and the base of the pull request.<p>- Chat with the bot: Supports conversation with the bot in the context of lines of code or entire files, helpful in providing context, generating test cases, and reducing code complexity.<p>- Smart review skipping: By default, skips in-depth review for simple changes (e.g., typo fixes) and when changes look good for the most part.<p>We would love the HN community to try it out in their GitHub repos and provide feedback! We will happily answer any technical questions regarding the sophisticated prompt engineering we did for this project.", "url": "https://coderabbit.ai/", "hn_url": "https://news.ycombinator.com/item?id=36725137", "score": 2, "num_comments": 4, "created_utc": 1689347605, "author": "gillh", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.758184"}
{"source": "HackerNews", "title": "Ask HN: Help with transpiling TypeScript to Golang and Python using LLMs", "text": "<i>The problem</i><p>I am looking for a service or effective technique using which I can get quick and reliable translation of our Node SDK (https:&#x2F;&#x2F;github.com&#x2F;supertokens&#x2F;supertokens-node) applied to our Python (https:&#x2F;&#x2F;github.com&#x2F;supertokens&#x2F;supertokens-python) and Golang (https:&#x2F;&#x2F;github.com&#x2F;supertokens&#x2F;supertokens-golang) SDK.<p>Our SDKs are not just wrappers around an OpenAPI spec, so we can\u2019t use existing tools to auto generate our backend SDK. Or even if we did, that would only generate a very tiny percentage of our SDK. Other than being API wrappers, our SDKs:<p>- Provide several overridable functions for users to hook into.<p>- Manage reading from the request and writing to the response objects of various web frameworks of these languages.<p>- Expose APIs to via a middleware (that again integrates into various web frameworks). Each API has a lot of logic that includes input checking, business logic of that API, calling various other APIs to do actions like send emails, and finally writing an output JSON.<p>Currently, we are hand writing each of these SDKs, and as you may imagine, it is very expensive. As a result, we have the Node SDK (which is our most used one) far ahead in terms of features compared to our other two SDKs.<p>As an example of the set of changes that need to be replicated in the other SDKs, have a look at this PR: https:&#x2F;&#x2F;github.com&#x2F;supertokens&#x2F;supertokens-node&#x2F;pull&#x2F;670&#x2F;files (many of the files are build files which can be ignored, but even then, it\u2019s 200+ files changed, a large chunk of which are adding tests).<p><i>What I have already tried</i><p>I have primarily played around with GPT-4 with different types of prompts for simpler PR changes (for example this PR: https:&#x2F;&#x2F;github.com&#x2F;supertokens&#x2F;supertokens-node&#x2F;pull&#x2F;782&#x2F;files).<p>For the TS code changes, I tried a prompt that gave the raw git diff of the node PR ", "url": "https://news.ycombinator.com/item?id=40274444", "hn_url": "https://news.ycombinator.com/item?id=40274444", "score": 2, "num_comments": 3, "created_utc": 1715002242, "author": "rishabhpoddar", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758192"}
{"source": "HackerNews", "title": "Show HN: ChainFactory \u2013 Run Structured LLM Inference with Easy Parallelism", "text": "Hi HN!<p>Disclaimer: I submitted another post about ChainFactory a few days ago.<p>Here&#x27;s what has changed since:<p>- Added hash based caching of auto-generated prompts and masks.<p>- Did some internal restructuring and cleanup.<p>- Updated the order in which README doc introduces concepts and terminology.<p>Posting this again because honestly, I am kinda puzzled about what to add&#x2F;fix&#x2F;change due to having 0 users and no genuine feedback.<p>By genuine feedback, I mean feedback from strangers who do not have a social pressure to be polite and pull punches.<p>Please take a look if you find this interesting and leave a comment. If you think it&#x27;s an deranged or stupid idea not worth your time, please at least leave a &#x27;no&#x27; - I&#x27;d still be delighted as it&#x27;s an honest opinion.<p>Thanks a lot!<p>PS: Is it okay to post updates and changes at regular intervals?", "url": "https://github.com/pankajgarkoti/ChainFactory", "hn_url": "https://news.ycombinator.com/item?id=41105402", "score": 2, "num_comments": 1, "created_utc": 1722304087, "author": "garkotipankaj", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.758202"}
{"source": "HackerNews", "title": "Show HN: Unified memory across all LLMs", "text": "Problem: Switching between Claude, ChatGPT, and Gemini meant losing all context. Every time I changed models, I had to start from scratch.<p>Solution: I built Hiperyon, a Chrome extension that creates unified cross-LLM memory. You chat normally, and your context transfers instantly when you switch models.<p>Impact:<p>Save time when juggling multiple LLMs<p>No more repeating the same prompts<p>Faster, smarter interactions across tools<p>About me:\nI\u2019m 19 and a solo founder. Built this in 2 months because context-switching between LLMs was killing my productivity.<p>Curious how you manage switching between LLMs, and what features you\u2019d want next!", "url": "https://hiperyon.com/", "hn_url": "https://news.ycombinator.com/item?id=46066882", "score": 2, "num_comments": 0, "created_utc": 1764230354, "author": "Ambroise75", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758218"}
{"source": "HackerNews", "title": "Show HN: Traceprompt \u2013 open-source SDK for tamper-proof LLM audit trails", "text": "Hi HN!<p>I\u2019m Paul, founder of Traceprompt. We\u2019re building an open-source SDK that wraps your LLM calls and generates tamper-proof audit trails, so you can prove who did what, when and with which model.<p>You can check out the Node SDK (more languages coming soon): <a href=\"https:&#x2F;&#x2F;github.com&#x2F;traceprompt&#x2F;traceprompt-node\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;traceprompt&#x2F;traceprompt-node</a><p>We built Traceprompt because LLMs are being used everywhere without a clear plan for audit and compliance. From research and discussions with other devs, I often see fintech and healthcare teams manually stitching together API Gateway, CloudWatch Logs and S3 buckets to track prompts&#x2F;responses and retention. This is both complex and costly as there&#x27;s little to no proof of immutability. Most current tools (Langfuse, Heliclone etc.) focus on LLM observability; few help generate verifiable evidence for compliance. That\u2019s where we come in.<p>To add, regulations are also moving in this direction (e.g. the EU AI Act requires logging for certain high-risk systems, HIPAA calls for audit controls and FINRA&#x2F;SEC rules push WORM-style retention). The goal is to make \u201cprove nothing changed\u201d boring.<p>Our SDK is simple:<p>1. BYOK architecture with AWS KMS. We never see plaintext prompts&#x2F;responses; only you can decrypt. Other KMS providers are on the roadmap.<p>2. Append-only, hash-chained logs with a public Merkle anchor for independent verification. Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;traceprompt&#x2F;open-anchors\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;traceprompt&#x2F;open-anchors</a><p>3. Audit packs: export CSV rows + proofs (and receipts) when someone asks \u201cwhat exactly happened on this day and time.\u201d You can also verify the audit packs \u2014 if a single byte was altered or a row removed by a bad actor, verification fails.<p>If &quot;AI audit trails&quot; are on your mind or on your roadmap, I&#x27;d love to talk", "url": "https://github.com/traceprompt/traceprompt-node", "hn_url": "https://news.ycombinator.com/item?id=44980272", "score": 2, "num_comments": 0, "created_utc": 1755827473, "author": "paulmbw", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.758226"}
{"source": "HackerNews", "title": "Show HN: Prototype for tamper-proof LLM logs \u2013 looking for early feedback", "text": "Hi HN,<p>I\u2019ve been exploring how to keep every LLM prompt and response in an audit-ready form. In regulated environments (health, fintech, EU AI Act) examiners now ask for content-level logs that are:<p>- Immutable \u2013 no user can \u201cUPDATE \u2026 WHERE id = \u2026\u201d the night before audit\n- Confidential \u2013 the logging vendor can\u2019t read your data\n- Verifiable \u2013 a third party can prove nothing was altered or deleted<p>Cloud audit logs are great for API calls, but they don\u2019t capture the text that left the model.  Teams I spoke to were DIY-ing S3 buckets, object-lock settings and spreadsheet trackers = nightmare.<p>Here is a high-level overview of how the prototype works:<p>- Client encrypts every prompt&#x2F;response with your cloud KMS key (BYOK).\n- Each log entry is written to an append-only store and linked so that any change breaks verification.\n- A public fingerprint of each batch is published so an auditor (or you) can confirm integrity without trusting the vendor.\n- When you need the content, you can decrypt a single row on demand under your own KMS permissions.<p>There are several reasons why I think this matters: regulations like HIPAA, SOC 2 CC7&#x2F;CC8, and the draft EU AI Act explicitly call for tamper-evident, long-term storage of AI interactions. Furthermore, insider edits or accidental (even intentional) purges can happen if you host logs in S3 or in your DB, and implementing crypto + anchoring + KMS plumbing in-house is non-trivial for most startups.<p>What feature (or missing piece) would turn this prototype into a useful tool for your team? And how are you handling \u201cprove-nothing-was-changed\u201d today, if at all?<p>I&#x27;d also love to demo the prototype we&#x27;ve built so far, just book some time with me here: <a href=\"https:&#x2F;&#x2F;cal.com&#x2F;traceprompt&#x2F;traceprompt-intro?overlayCalendar=true\" rel=\"nofollow\">https:&#x2F;&#x2F;cal.com&#x2F;traceprompt&#x2F;traceprompt-intro?overlayCalenda...</a><p>Thanks!<p>Paul", "url": "https://news.ycombinator.com/item?id=44245942", "hn_url": "https://news.ycombinator.com/item?id=44245942", "score": 2, "num_comments": 0, "created_utc": 1749636360, "author": "paulmbw", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.758236"}
{"source": "HackerNews", "title": "Show HN: Raink \u2013 Document ranker using LLMs", "text": "I think a lot of AI-augmented security problems can be decomposed into &quot;show me the best thing in this list of things&quot;:<p>- the changed function in a patch diff that most closely relates to a given security advisory<p>- the injection point in a webapp that seems most likely to cause a state change on the backend<p>- the static code analyzer result that would have most severe impact if a sink were actually reachable<p>It&#x27;s notoriously difficult to get an LLM to seriously consider all items when presented with a big list of input\u2014so I built raink, a CLI tool to harness LLMs for general purpose document ranking.<p>Blog post here: <a href=\"https:&#x2F;&#x2F;bishopfox.com&#x2F;blog&#x2F;raink-llms-document-ranking\" rel=\"nofollow\">https:&#x2F;&#x2F;bishopfox.com&#x2F;blog&#x2F;raink-llms-document-ranking</a>", "url": "https://github.com/BishopFox/raink", "hn_url": "https://news.ycombinator.com/item?id=42714311", "score": 2, "num_comments": 0, "created_utc": 1736963051, "author": "noperator", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.758247"}
{"source": "HackerNews", "title": "Show HN: I made a simple unified LLM client with tool calling and vision support", "text": "So I could get rid of Langchain and not have to write response.choices[0].message.content in a different way every time I changed models.", "url": "https://github.com/piEsposito/tiny-ai-client", "hn_url": "https://news.ycombinator.com/item?id=40576026", "score": 2, "num_comments": 0, "created_utc": 1717517348, "author": "someguy12345678", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.758254"}
{"source": "HackerNews", "title": "Show HN: A context-aware semantic cache for reducing LLM app latency and cost", "text": "We&#x27;re Tom and Adrian, the cofounders of Canonical AI. We were building a conversational AI product and wanted to use semantic caching. We tried out a few different projects, but none of them were accurate enough. The problem with the semantic caches we tried was that they didn&#x27;t have a sense of the context of the user query. That is, the same user query could mean two different things, depending on what the query is referencing.<p>So we changed course and started working on a semantic cache that understands the context of the user query. We&#x27;ve developed a number of different methods to make the cache more aware of the context. These methods include multi-tenancy (i.e., user-defined cache scopes), multi-turn cache keys, metadata tagging, etc.<p>We&#x27;d love to hear your thoughts on it!", "url": "https://github.com/Canonical-AI-Inc/canonical", "hn_url": "https://news.ycombinator.com/item?id=40575871", "score": 2, "num_comments": 0, "created_utc": 1717516413, "author": "tmshapland", "ai_tool": "General", "scraped_at": "2025-12-17T17:19:02.758260"}
{"source": "HackerNews", "title": "Claude AI to process secret government data through new Palantir deal", "text": "", "url": "https://arstechnica.com/ai/2024/11/safe-ai-champ-anthropic-teams-up-with-defense-giant-palantir-in-new-deal/", "hn_url": "https://news.ycombinator.com/item?id=42091043", "score": 239, "num_comments": 184, "created_utc": 1731105740, "author": "lawls", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758277"}
{"source": "HackerNews", "title": "Claude AI built me a React app to compare maps side by side", "text": "", "url": "https://github.com/veloplanner/map-matrix", "hn_url": "https://news.ycombinator.com/item?id=42164141", "score": 222, "num_comments": 201, "created_utc": 1731850779, "author": "caspg", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758290"}
{"source": "HackerNews", "title": "API, Claude.ai, and Console services impacted [resolved]", "text": "", "url": "https://status.anthropic.com/incidents/k6gkm2b8cjk9", "hn_url": "https://news.ycombinator.com/item?id=45200118", "score": 161, "num_comments": 79, "created_utc": 1757521894, "author": "rob", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758295"}
{"source": "HackerNews", "title": "My experience trying to write human-sounding articles using Claude AI", "text": "", "url": "https://idratherbewriting.com/blog/writing-full-length-articles-with-claude-ai", "hn_url": "https://news.ycombinator.com/item?id=38382067", "score": 111, "num_comments": 55, "created_utc": 1700673737, "author": "dv-tw", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758300"}
{"source": "HackerNews", "title": "Claude.ai Is Down", "text": "", "url": "https://claude.ai", "hn_url": "https://news.ycombinator.com/item?id=45769901", "score": 57, "num_comments": 3, "created_utc": 1761901983, "author": "imalerba", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758305"}
{"source": "HackerNews", "title": "Show HN: I built a Claude AI chat interface to bypass platform limits", "text": "I got frustrated with Claude&#x27;s official platform limitations - conversations disappearing, no customization options, and clunky file handling.<p>So I built my own interface over a weekend!<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;chihebnabil&#x2F;claude-ui\">https:&#x2F;&#x2F;github.com&#x2F;chihebnabil&#x2F;claude-ui</a><p>What it does:<p>- Saves all conversations locally (SQLite + Drizzle ORM)\n- Lets you customize Claude&#x27;s personality per chat\n- Handles file attachments properly + caching input tokens\n- Dark&#x2F;light mode\n- No conversation limits\n- Markdown &amp; code syntax highlighting<p>Tech stack is pretty simple:<p>- Nuxt 3 for the frontend\n- Anthropic&#x27;s SDK for Claude integration\n- @nuxt&#x2F;ui for components\n- Local SQLite DB<p>Happy to answer any questions!", "url": "https://github.com/chihebnabil/claude-ui", "hn_url": "https://news.ycombinator.com/item?id=42106890", "score": 39, "num_comments": 14, "created_utc": 1731330975, "author": "NabilChiheb", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758310"}
{"source": "HackerNews", "title": "Show HN: I build a Fantasy NHL app in 3 days with Claude AI", "text": "I am not from North America, and moved there a couple years ago. After being invited to the first fantasy league and seeing the platform they were using, I couldn&#x27;t bring myself to check it every day. An excel sheet would have been more appealing to use than this.<p>So I decided to create my own. But on the side? This would take ages. I am very confident with Rust and JavaScript, but it still takes ages to build something like that.<p>Good prompts, and a few long nights later, and I could create something fun and easy to use.<p>Have a look:\n<a href=\"https:&#x2F;&#x2F;fantasy-frontend.fly.dev&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;fantasy-frontend.fly.dev&#x2F;</a><p>The frontend is in React, the backend in Rust. I deployed both via fly.io. It was so simple and fast, it was shocking.<p>After it was deployed, I took 2-3 days to refactor everything and made it neat and tidy, so I could possibly open it up for general use with accounts etc.<p>The first time I built something with the help of AI not just for me.<p>The biggest help was certainly the UI and styling. I was never good at that. The first draft looked rough. I fed it some screenshots from NHL.com and told the model to &quot;make it look nicer&quot;. What you see is I think the 20th iteration of the app, slowly improving, fixing bugs etc. But 90% with the help of AI.<p>I could have done 98% myself (except the styling part). And after each working iteration, I spend quite some time cleaning up so I can  build on top of that.<p>The beauty? The cleaner, more modular code base saved tokens and made it easier for the model to refactor and understand. Strictly typed (TypeScritp in the frontend, Rust in the backend) helped as well!", "url": "https://news.ycombinator.com/item?id=43805275", "hn_url": "https://news.ycombinator.com/item?id=43805275", "score": 35, "num_comments": 15, "created_utc": 1745687047, "author": "recvonline", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758318"}
{"source": "HackerNews", "title": "Is Cloudflare Down Again? Also, DownDetector/Claude.ai/LinkedIn?", "text": "I was writing a blogpost on Medium and I noticed errors, tried to open LinkedIn? down. tried downdetector? down. Claude.ai is also down", "url": "https://news.ycombinator.com/item?id=46158275", "hn_url": "https://news.ycombinator.com/item?id=46158275", "score": 31, "num_comments": 4, "created_utc": 1764924947, "author": "dfasoro", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758327"}
{"source": "HackerNews", "title": "Anthropic AI's Claude early access for everyone now available", "text": "", "url": "https://twitter.com/AnthropicAI/status/1635679544521920512", "hn_url": "https://news.ycombinator.com/item?id=35154149", "score": 25, "num_comments": 3, "created_utc": 1678811514, "author": "staranjeet", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758333"}
{"source": "HackerNews", "title": "Claude.ai, Console, and API not available", "text": "", "url": "https://status.anthropic.com/incidents/rjjg3fzd2spp", "hn_url": "https://news.ycombinator.com/item?id=43397664", "score": 23, "num_comments": 10, "created_utc": 1742293269, "author": "StanAngeloff", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758338"}
{"source": "HackerNews", "title": "The Analysis Tool in Claude.ai", "text": "", "url": "https://www.anthropic.com/news/analysis-tool", "hn_url": "https://news.ycombinator.com/item?id=41936248", "score": 16, "num_comments": 6, "created_utc": 1729782348, "author": "brianjking", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758343"}
{"source": "HackerNews", "title": "Claude.ai and console.anthropic.com are down", "text": "", "url": "https://status.anthropic.com/", "hn_url": "https://news.ycombinator.com/item?id=44111298", "score": 16, "num_comments": 4, "created_utc": 1748385682, "author": "doener", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758348"}
{"source": "HackerNews", "title": "Windsurf says Anthropic is limiting its direct access to Claude AI models", "text": "", "url": "https://techcrunch.com/2025/06/03/windsurf-says-anthropic-is-limiting-its-direct-access-to-claude-ai-models/", "hn_url": "https://news.ycombinator.com/item?id=44176321", "score": 14, "num_comments": 1, "created_utc": 1748998887, "author": "mikece", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758353"}
{"source": "HackerNews", "title": "Show HN: 8-Bit Spelling Game I Built for My Daughter Using Claude AI", "text": "I had a lot of fun with this one. She&#x27;s used it several times, and I watch, to see what subtle bugs or ux issues there may be.<p>And when she gets on the bus I fix them quickly before work.<p>It&#x27;s been a fun game to create where it gives here immediate feedback and she&#x27;s willing to study more.<p>Her test is this Friday. <i>fingers crossed</i> that it helped her!", "url": "https://kbr.sh/post/2025/May/21/8-bit-spelling-game-built-with-claude/", "hn_url": "https://news.ycombinator.com/item?id=44062264", "score": 13, "num_comments": 4, "created_utc": 1747923285, "author": "program247365", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758358"}
{"source": "HackerNews", "title": "New Claude AI can take over your computer", "text": "", "url": "https://newatlas.com/ai-humanoids/anthropic-claude-computer-use-agent-ai/", "hn_url": "https://news.ycombinator.com/item?id=41922605", "score": 12, "num_comments": 8, "created_utc": 1729667465, "author": "geox", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758373"}
{"source": "HackerNews", "title": "Claude 3 AI catches researchers testing it", "text": "", "url": "https://newatlas.com/technology/anthropic-claude-3/", "hn_url": "https://news.ycombinator.com/item?id=39612829", "score": 12, "num_comments": 4, "created_utc": 1709705408, "author": "elromulous", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758379"}
{"source": "HackerNews", "title": "Anthropic\u2019s Claude AI can digest an entire book like The Great Gatsby in seconds", "text": "", "url": "https://arstechnica.com/information-technology/2023/05/anthropics-claude-ai-can-now-digest-an-entire-book-like-the-great-gatsby-in-seconds/", "hn_url": "https://news.ycombinator.com/item?id=35941920", "score": 11, "num_comments": 7, "created_utc": 1684103289, "author": "rbanffy", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758384"}
{"source": "HackerNews", "title": "Banned from Claude.ai after first prompt without refund", "text": "cross-posting here, since some Anthropic employees browse HN and may be able to fix their abuse heuristics?<p>I paid for Claude Pro yesterday (excited to use the model as it seems quite good!) and asked it a question about symmetric groups in abstract algebra. I was automatically banned for TOS violations and not given any refund. I&#x27;m not using a VPN, and I&#x27;m in a supported country.<p>It seems to be a widespread(?) bug with their abuse model (from a skim of the &#x2F;r&#x2F;ClaudeAI subreddit: https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ClaudeAI&#x2F;search&#x2F;?q=ban&amp;sort=top), acknowledged by their community support team 2 weeks ago. But it seems they haven&#x27;t been able to fix their model, and continue selling paid subscriptions. Their TOS says they won&#x27;t refund payments if they ban an account for purported &quot;TOS violations&quot;.<p>I contacted support but got an automatic reply saying they&#x27;re facing a high volume of queries.<p>sorta feels indistinguishable from a scam to be honest... it should at least be possible to get in touch with a human when things go wrong.", "url": "https://news.ycombinator.com/item?id=39793054", "hn_url": "https://news.ycombinator.com/item?id=39793054", "score": 11, "num_comments": 2, "created_utc": 1711129638, "author": "bobbybotty", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758390"}
{"source": "HackerNews", "title": "Anthropic's Claude AI Chatbot Now Has a Mac App, but It's an Electron Turd", "text": "", "url": "https://daringfireball.net/linked/2024/10/31/anthropic-mac-app-electron-turd", "hn_url": "https://news.ycombinator.com/item?id=42014869", "score": 9, "num_comments": 2, "created_utc": 1730447878, "author": "frizlab", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758398"}
{"source": "HackerNews", "title": "Show HN: Claudio \u2013 Audio Input for Claude.ai", "text": "I built Claudio to solve a simple problem: typing is slow when you have\n  complex thoughts to share with Claude. This Chrome extension adds a\n  microphone button to Claude.ai that uses OpenAI Whisper for transcription.<p><pre><code>  Key features:\n  - One-click voice recording with intelligent progress tracking\n  - Audio file upload support (perfect for mobile voice notes \u2192 desktop Claude workflow)\n  - Speed control (1-2x compression) to reduce API costs\n  - Private and secure - your OpenAI API key stays local\n  - Real-time transcription stats and performance analytics\n\n  Latest v1.2.1 fixes:\n  - Improved audio duration detection using Web Audio API\n  - Fixed NaN calculations in transcription time estimates\n  - Better error handling for edge cases\n\n  The extension integrates seamlessly into Claude&#x27;s interface - just click\n  the mic button, speak naturally, and your voice becomes text. Especially\n  useful for content creators, researchers, and anyone who thinks faster\n  than they type.\n\n  Use cases I&#x27;ve found most valuable:\n  - Recording ideas during walks&#x2F;commutes, then uploading the audio files to\n   Claude desktop\n  - Dictating complex code explanations and documentation\n  - Converting meeting recordings into structured notes\n  - Hands-free email composition\n\n  Installation takes under 2 minutes via Chrome&#x27;s developer mode. The\n  extension is free and open-source.\n\n  Download: http:&#x2F;&#x2F;earthpilot.ai&#x2F;claudio&#x2F;\n\n  What voice-to-text workflows have you found most useful in your daily\n  work?\n\n  ---\n  Independent project, not affiliated with Anthropic or OpenAI. Uses your \n  own OpenAI API key.\n</code></pre>\nIf you&#x27;d like an invite to our weekly AI Playground as my VIP visit <a href=\"http:&#x2F;&#x2F;earthpilot.ai&#x2F;play\" rel=\"nofollow\">http:&#x2F;&#x2F;earthpilot.ai&#x2F;play</a>", "url": "https://earthpilot.ai/claudio/", "hn_url": "https://news.ycombinator.com/item?id=45145344", "score": 8, "num_comments": 2, "created_utc": 1757118569, "author": "ada1981", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758404"}
{"source": "HackerNews", "title": "Elevated Errors on Claude.ai", "text": "", "url": "https://status.claude.com/incidents/qj71q3gqvvlk", "hn_url": "https://news.ycombinator.com/item?id=46123291", "score": 7, "num_comments": 2, "created_utc": 1764694466, "author": "l2dy", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758414"}
{"source": "HackerNews", "title": "Anthropic claims of Claude AI-automated cyberattacks met with doubt", "text": "", "url": "https://www.bleepingcomputer.com/news/security/anthropic-claims-of-claude-ai-automated-cyberattacks-met-with-doubt/", "hn_url": "https://news.ycombinator.com/item?id=45930236", "score": 6, "num_comments": 2, "created_utc": 1763145599, "author": "speckx", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758422"}
{"source": "HackerNews", "title": "Show HN: Gemini vs. ChatGPT vs. Claude AI", "text": "Hey HN, I just updated my project that compares some LLMs. It uses your prompt for all the models and runs at the same time. You can see the results being generated in real-time and decide what&#x27;s the best for your use case. I&#x27;m open to any suggestions and feedback. Thanks!", "url": "https://geminivsgpt.com/", "hn_url": "https://news.ycombinator.com/item?id=39669644", "score": 6, "num_comments": 2, "created_utc": 1710172061, "author": "jeanmayer", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758427"}
{"source": "HackerNews", "title": "Anthropic blames ClaudeAI for embarrassing unintentional mistake in legal filing", "text": "", "url": "https://www.theverge.com/news/668315/anthropic-claude-legal-filing-citation-error", "hn_url": "https://news.ycombinator.com/item?id=44025967", "score": 5, "num_comments": 1, "created_utc": 1747620566, "author": "croes", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758433"}
{"source": "HackerNews", "title": "Claude's new AI file creation feature ships with deep security risks built in", "text": "", "url": "https://arstechnica.com/information-technology/2025/09/anthropics-new-claude-feature-can-leak-data-users-told-to-monitor-chats-closely/", "hn_url": "https://news.ycombinator.com/item?id=45195047", "score": 5, "num_comments": 0, "created_utc": 1757494444, "author": "consumer451", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758438"}
{"source": "HackerNews", "title": "Claude.ai Is Down", "text": "", "url": "https://downdetector.com/status/anthropic/", "hn_url": "https://news.ycombinator.com/item?id=44111270", "score": 5, "num_comments": 0, "created_utc": 1748385394, "author": "esaym", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758444"}
{"source": "HackerNews", "title": "A new generation of AIs: Claude 3.7 and Grok 3", "text": "", "url": "https://www.oneusefulthing.org/p/a-new-generation-of-ais-claude-37", "hn_url": "https://news.ycombinator.com/item?id=43167907", "score": 5, "num_comments": 0, "created_utc": 1740454924, "author": "spenvo", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758449"}
{"source": "HackerNews", "title": "A Team Lead Uses Claude AI as His Virtual Senior Developer [video]", "text": "", "url": "https://www.youtube.com/watch?v=XexwYB-EqT0", "hn_url": "https://news.ycombinator.com/item?id=41095803", "score": 4, "num_comments": 0, "created_utc": 1722199223, "author": "johnwheeler", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758463"}
{"source": "HackerNews", "title": "Is there any way to get more rate limit for Claude AI, without paying", "text": "", "url": "https://news.ycombinator.com/item?id=43170044", "hn_url": "https://news.ycombinator.com/item?id=43170044", "score": 3, "num_comments": 7, "created_utc": 1740477801, "author": "animator2024", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758468"}
{"source": "HackerNews", "title": "Is anybody having issues with Claude.ai Sonnet now?", "text": "The status site says that it&#x27;s green, but I keep getting retries when I try to query Sonnet for even the simplest things. Opus and Haiku seem to be working. Thanks!", "url": "https://news.ycombinator.com/item?id=45846664", "hn_url": "https://news.ycombinator.com/item?id=45846664", "score": 3, "num_comments": 5, "created_utc": 1762525276, "author": "0dj0bz", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758473"}
{"source": "HackerNews", "title": "Show HN: PageGen-10x Faster Page Generation with Claude AI, React and Shadcn UI", "text": "10x Faster Page Generation with PageGen AI, Generate beautiful, production-ready web pages from text, screenshot, image, file and url with one click", "url": "https://pagegen.ai", "hn_url": "https://news.ycombinator.com/item?id=42100575", "score": 3, "num_comments": 5, "created_utc": 1731250718, "author": "ahaapple", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758479"}
{"source": "HackerNews", "title": "Claude.ai do not deliver what I payed for", "text": "Hi,<p>is someone else encountering difficulties in usage? I have a pro-plan - even if its not the MAX, I still pay for Opus 4 model and can&#x27;t use it since hours. Its &quot;overloaded&quot; - without my money, it wouldn&#x27;t even load - is Anthropic misunderstanding this fact???<p>I&#x27;ll cancel my subscription. I can&#x27;t use Opus 4 without paying either. That&#x27;s such a bad move.<p>What legal options do I have to get my money back or a compensation for not being able to use what I pay for? I&#x27;m really upset on such behavior.<p>I don&#x27;t do Claude Code or do have a large codebase, nor do I feed in image-files or do voice data - I just want it to help me code in my hobby project wit &lt; 2000 lines of python.<p>I hate it!", "url": "https://news.ycombinator.com/item?id=44735552", "hn_url": "https://news.ycombinator.com/item?id=44735552", "score": 3, "num_comments": 4, "created_utc": 1753889533, "author": "theGeatZhopa", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758487"}
{"source": "HackerNews", "title": "Anthropic Says Claude AI Powered 90% of Chinese Espionage Campaign", "text": "", "url": "https://www.securityweek.com/anthropic-says-claude-ai-powered-90-of-chinese-espionage-campaign/", "hn_url": "https://news.ycombinator.com/item?id=45939487", "score": 3, "num_comments": 2, "created_utc": 1763231492, "author": "Bender", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758494"}
{"source": "HackerNews", "title": "Claude AI Nuked My Git Repo", "text": "", "url": "https://geextor.com/2025/08/21/how-i-handed-an-ai-the-keys-to-my-repo-and-it-nuked-everything-instead/", "hn_url": "https://news.ycombinator.com/item?id=44979816", "score": 3, "num_comments": 2, "created_utc": 1755822491, "author": "randomnumber314", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758499"}
{"source": "HackerNews", "title": "Anthropic's AI Claude tried to contact the FBI", "text": "", "url": "https://www.yahoo.com/news/videos/why-anthropics-ai-claude-tried-002808728.html", "hn_url": "https://news.ycombinator.com/item?id=45954110", "score": 3, "num_comments": 1, "created_utc": 1763391261, "author": "abixb", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758504"}
{"source": "HackerNews", "title": "Claude Skills Hub \u2013 A Directory for Claude AI Skills", "text": "", "url": "https://claudeskills.info/", "hn_url": "https://news.ycombinator.com/item?id=45638974", "score": 3, "num_comments": 1, "created_utc": 1760917033, "author": "ursaiceice", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758508"}
{"source": "HackerNews", "title": "I Put Claude AI into Jail and Let Him Code Anyays", "text": "", "url": "https://www.indiehackers.com/post/why-i-put-chatgpt-into-jail-and-let-him-code-anyays-4e2b915f15", "hn_url": "https://news.ycombinator.com/item?id=45247968", "score": 3, "num_comments": 1, "created_utc": 1757930326, "author": "scrumbuddy_ai", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758513"}
{"source": "HackerNews", "title": "Anthropic's Claude AI became a terrible business owner in an experiment", "text": "", "url": "https://techcrunch.com/2025/06/28/anthropics-claude-ai-became-a-terrible-business-owner-in-experiment-that-got-weird/", "hn_url": "https://news.ycombinator.com/item?id=44420602", "score": 3, "num_comments": 1, "created_utc": 1751270051, "author": "gdrift", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758518"}
{"source": "HackerNews", "title": "Ask HN: Claude AI Unusable ?", "text": "I was a happy paying user of ClaudeAI.\nBut since 1 month, the service is very awfull. Most of the time, during the day (Europe time) I have limitation on response level even more and more fail &#x2F; try later message.\nHow Claude is working for you ?", "url": "https://news.ycombinator.com/item?id=42399740", "hn_url": "https://news.ycombinator.com/item?id=42399740", "score": 3, "num_comments": 1, "created_utc": 1734015968, "author": "oliviergg", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758523"}
{"source": "HackerNews", "title": "Show HN: Game Created with Claude.ai and Midjouney", "text": "", "url": "https://apps.apple.com/us/app/super-ball-brick-crusher/id6736870504", "hn_url": "https://news.ycombinator.com/item?id=42322983", "score": 3, "num_comments": 1, "created_utc": 1733353139, "author": "lpeancovschi", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758529"}
{"source": "HackerNews", "title": "Claude.ai: Introducing Google Docs in Chats and Projects", "text": "", "url": "https://support.anthropic.com/en/articles/10168395-setting-up-integrations-on-claude-ai", "hn_url": "https://news.ycombinator.com/item?id=42214285", "score": 3, "num_comments": 1, "created_utc": 1732287216, "author": "infamia", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758536"}
{"source": "HackerNews", "title": "Authors sue Claude AI chatbot creator Anthropic for copyright infringement", "text": "", "url": "https://apnews.com/article/authors-sue-anthropic-claude-ai-chatbot-chatgpt-copyright-54ae787070bdfc8019ab29b70487c02d", "hn_url": "https://news.ycombinator.com/item?id=41305221", "score": 3, "num_comments": 1, "created_utc": 1724197282, "author": "tagawa", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758541"}
{"source": "HackerNews", "title": "Show HN: We open-sourced our internal tool for scoring PRs with Claude AI", "text": "Hi HN! I&#x27;m sharing MergeMint, an open-source platform we built at TextCortex AI to automatically evaluate and score pull requests using Claude AI.<p>The problem we had: Our engineering team lacked visibility into contribution impact, and performance reviews felt subjective. We wanted objective metrics without the overhead of manual PR reviews.<p>How it works: When a PR merges, MergeMint analyzes the diff, linked issues, and commits using Claude AI. It classifies component&#x2F;severity, calculates a score, posts feedback on the PR, and updates team leaderboards.<p>The results after 6 months:\n\u2022 3x increase in developer engagement with our internal bug bounty program\n\u2022 Team members actively compete on leaderboards (gamification really works!)\n\u2022 Performance reviews now backed by concrete contribution data\n\u2022 We caught and rewarded high-impact work that was flying under the radar<p>The scoring is fully configurable \u2013 we defined our components (auth, API, UI) with multipliers and severity levels (P0-P3) with base points. Claude does the classification, we control the weights.<p>Honestly, the gamification aspect surprised us the most. Developers started paying more attention to linking issues, writing better PR descriptions, and picking up high-priority work.<p>Tech stack: Next.js 15, Supabase (PostgreSQL), Anthropic Claude, Tailwind v4. Fully self-hostable with Docker.<p>We&#x27;re open-sourcing it because it&#x27;s been transformative for our team, and we think other engineering orgs could benefit.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;MergeMint&#x2F;mergemint-app\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;MergeMint&#x2F;mergemint-app</a>\nFree SaaS version: <a href=\"https:&#x2F;&#x2F;mergemint.dev\" rel=\"nofollow\">https:&#x2F;&#x2F;mergemint.dev</a><p>Happy to answer questions about our experience deploying this in production or the technical implementation!", "url": "https://github.com/MergeMint/mergemint-app", "hn_url": "https://news.ycombinator.com/item?id=46221321", "score": 3, "num_comments": 0, "created_utc": 1765390791, "author": "textcortex", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758546"}
{"source": "HackerNews", "title": "Anthropic thwarts hacker attempts to misuse Claude AI for cybercrime", "text": "", "url": "https://www.reuters.com/business/retail-consumer/anthropic-thwarts-hacker-attempts-misuse-claude-ai-cybercrime-2025-08-27/", "hn_url": "https://news.ycombinator.com/item?id=45038102", "score": 3, "num_comments": 0, "created_utc": 1756293784, "author": "c420", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758570"}
{"source": "HackerNews", "title": "claude-mcp: Browser extension to enable MCP in claude.ai", "text": "", "url": "https://github.com/dnakov/claude-mcp", "hn_url": "https://news.ycombinator.com/item?id=43670791", "score": 3, "num_comments": 0, "created_utc": 1744529058, "author": "pizza", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758576"}
{"source": "HackerNews", "title": "Claude AI Is Not Production Ready", "text": "", "url": "https://mydevmentor.com/blog/claude-ai-is-not-production-ready", "hn_url": "https://news.ycombinator.com/item?id=42377414", "score": 3, "num_comments": 0, "created_utc": 1733842513, "author": "NabilChiheb", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758581"}
{"source": "HackerNews", "title": "Anthropic says Claude AI can match your unique writing style", "text": "", "url": "https://www.theverge.com/2024/11/26/24306575/anthropic-claude-ai-custom-style-presets", "hn_url": "https://news.ycombinator.com/item?id=42248396", "score": 3, "num_comments": 0, "created_utc": 1732645535, "author": "elashri", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758586"}
{"source": "HackerNews", "title": "Codifying a ChatGPT workflow into a malleable GUI", "text": "", "url": "https://www.geoffreylitt.com/2023/07/25/building-personal-tools-on-the-fly-with-llms.html", "hn_url": "https://news.ycombinator.com/item?id=36896305", "score": 3, "num_comments": 0, "created_utc": 1690476255, "author": "samwillis", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758591"}
{"source": "HackerNews", "title": "ChatGPT Creating Workflows", "text": "Human:<p>give me a Netflix conductor workflow json to get user details and based the preference send email to sms<p>ChatGPT:\n{\n  &quot;name&quot;: &quot;userCommunicationWorkflow&quot;,\n  &quot;description&quot;: &quot;Workflow to fetch user details and send communication based on preference&quot;,\n  &quot;version&quot;: 1,\n  &quot;tasks&quot;: [\n    {\n      &quot;name&quot;: &quot;getUserDetails&quot;,\n      &quot;taskReferenceName&quot;: &quot;getUserDetailsRef&quot;,\n      &quot;inputParameters&quot;: {\n        &quot;userId&quot;: &quot;${workflow.input.userId}&quot;\n      },\n      &quot;type&quot;: &quot;HTTP&quot;,\n      &quot;http_request&quot;: {\n        &quot;uri&quot;: &quot;http:&#x2F;&#x2F;example.com&#x2F;api&#x2F;users&#x2F;${workflow.input.userId}&quot;,\n        &quot;method&quot;: &quot;GET&quot;\n      }\n    },\n    {\n      &quot;name&quot;: &quot;decisionTask&quot;,\n      &quot;taskReferenceName&quot;: &quot;decisionTaskRef&quot;,\n      &quot;inputParameters&quot;: {\n        &quot;userPreference&quot;: &quot;${getUserDetailsRef.output.preference}&quot;\n      },\n      &quot;type&quot;: &quot;DECISION&quot;,\n      &quot;decisionCases&quot;: {\n        &quot;EMAIL&quot;: [\n          {\n            &quot;name&quot;: &quot;sendEmail&quot;,\n            &quot;taskReferenceName&quot;: &quot;sendEmailRef&quot;,\n            &quot;inputParameters&quot;: {\n              &quot;emailAddress&quot;: &quot;${getUserDetailsRef.output.email}&quot;,\n              &quot;message&quot;: &quot;Your personalized message here&quot;\n            },\n            &quot;type&quot;: &quot;HTTP&quot;,\n            &quot;http_request&quot;: {\n              &quot;uri&quot;: &quot;http:&#x2F;&#x2F;emailservice.com&#x2F;send&quot;,\n              &quot;method&quot;: &quot;POST&quot;,\n              &quot;body&quot;: {\n                &quot;to&quot;: &quot;${workflow.input.emailAddress}&quot;,\n                &quot;subject&quot;: &quot;Message Subject&quot;,\n                &quot;body&quot;: &q", "url": "https://news.ycombinator.com/item?id=40460916", "hn_url": "https://news.ycombinator.com/item?id=40460916", "score": 2, "num_comments": 0, "created_utc": 1716505305, "author": "orkes", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758596"}
{"source": "HackerNews", "title": "Show HN: AINativeKit-UI \u2013 Turn MCP JSON into ChatGPT App UIs", "text": "I&#x27;ve been working with the new ChatGPT Apps SDK from OpenAI and found that turning MCP JSON results into usable UI takes a lot of repetitive React work.<p>So I built <i>AINativeKit-UI</i>, an open-source React component library that:<p>- Instantly maps structured MCP JSON -&gt; UI<p>- Works directly with the ChatGPT Apps SDK<p>- Adapts beautifully to <i>mobile and desktop</i> ChatGPT interfaces<p>- Follows OpenAI\u2019s Figma-aligned design system for consistency<p>- Includes prebuilt Cards, Lists, Maps, and Carousels<p>- Is fully TypeScript, accessible, and MIT licensed<p>Demo: ainativekit.com<p>Code: github.com&#x2F;AINativeKit&#x2F;ainativekit-ui<p>The goal is to help developers focus on AI logic instead of UI wiring.<p>Would love your thoughts on:<p>- What components or patterns should come next?<p>- How could this integrate better with your ChatGPT App workflow?", "url": "https://github.com/AINativeKit/ainativekit-ui", "hn_url": "https://news.ycombinator.com/item?id=45753972", "score": 2, "num_comments": 0, "created_utc": 1761777245, "author": "jakelin", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758606"}
{"source": "HackerNews", "title": "Show HN: CompareGPT\u2013 Turn AI hallucinations into credits (and even cash rewards)", "text": "Hi HN  I\u2019m Tina.\nWe all know LLM hallucinations can be funny \u2014 but also frustrating and risky. Instead of ignoring them, I thought: what if we could collect them and make it useful?\nThat\u2019s why I\u2019m building CompareGPT.io. The platform does two things:\n Multi-model comparison to reduce hallucinations in real workflows (ChatGPT, Gemini, Claude, Grok &amp; more).\n A new campaign: users can submit hallucination cases \u2192 earn credits \u2192 unlock API usage \u2192 even convert credits into real cash rewards.\nThe goal is to make AI more trustworthy, while giving users a fun and rewarding way to participate.\n We just opened the waitlist, with referral links so anyone can share and grow credits faster.\nI\u2019d love feedback from this community:\nWould you consider multi-model consistency + crowdsourced hallucination collection as a useful guardrail?\nDo you see a future for credit-based incentives in AI platforms?\nThanks!", "url": "https://news.ycombinator.com/item?id=45206038", "hn_url": "https://news.ycombinator.com/item?id=45206038", "score": 1, "num_comments": 1, "created_utc": 1757550066, "author": "tinatina_AI", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758613"}
{"source": "HackerNews", "title": "Ask HN: How do you use ChatGPT in your workflow?", "text": "In a few threads recently a lot of devs state they use GPT to improve their efficiency and become 1.5x engineers etc.<p>Could you please elaborate and give practical examples on how you do that?<p>What type of tasks? Alt-tab between Windows and copy paste etc? Prompt engineering? How do you work with it in large projects etc?<p>Reference thread:\nhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36338187", "url": "https://news.ycombinator.com/item?id=36343441", "hn_url": "https://news.ycombinator.com/item?id=36343441", "score": 2, "num_comments": 1, "created_utc": 1686848333, "author": "euph0ria", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758624"}
{"source": "HackerNews", "title": "How to Use ChatGPT in Your Workflow", "text": "", "url": "https://www.inc.com/hillel-fuld/5-ways-to-use-chatgpt-in-your-workflow.html", "hn_url": "https://news.ycombinator.com/item?id=34081306", "score": 2, "num_comments": 1, "created_utc": 1671633836, "author": "ynwa1994", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758630"}
{"source": "HackerNews", "title": "Levelsio shocked by ChatGPT to Suno workflow: Real passable tracks", "text": "", "url": "https://twitter.com/levelsio/status/1957155181591777503", "hn_url": "https://news.ycombinator.com/item?id=44992991", "score": 2, "num_comments": 0, "created_utc": 1755921207, "author": "kurinikku", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758635"}
{"source": "HackerNews", "title": "Show HN: Agentflow \u2013 Run Complex LLM Workflows from Simple JSON", "text": "So, it feels like this should exist. But I couldn&#x27;t find it. So I tried to build it.<p>Agentflow lets you run complex LLM workflows from a simple JSON file. This can be as little as a list of tasks. Tasks can include variables, so you can reuse workflows for different outputs by providing different variable values. They can also include custom functions, so you can go beyond text generation to do anything you want to write a function for.<p>Someone might say: &quot;Why not just use ChatGPT?&quot; Among other reasons, I&#x27;d say that you can&#x27;t template a workflow with ChatGPT, trigger it with different variable values, easily add in custom functions, or force the use of custom functions for steps in the workflow.<p>Someone might also say: &quot;Then why not use Auto-GPT or BabyAGI?&quot; Among other reasons, I&#x27;d say you can&#x27;t if you want consistency because these tools operate autonomously, creating and executing their own tasks. Agentflow, on the other and, lets you define a step-by-step workflow to give you more control.<p>I&#x27;d like to do more with this, including adding more custom functions, and more examples, and more ways to trigger workflows (such as in response to events). But first, I want to make sure I&#x27;m not wasting my time! For starters, if something like this already exists, please tell me.", "url": "https://github.com/simonmesmith/agentflow", "hn_url": "https://news.ycombinator.com/item?id=37052979", "score": 51, "num_comments": 23, "created_utc": 1691517433, "author": "simonmesmith", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758648"}
{"source": "HackerNews", "title": "Ask HN: Do you think it's bad for businesses to tout they use AI for everything?", "text": "For a business, do you think it&#x27;s &quot;bad&quot; to proudly tout that you use AI for everything?<p>I&#x27;ll start by saying I know it depends on the target market, etc... but curious what this group thinks even though I know this audience isn&#x27;t representative of the general public.<p>*Context:*\nI built Text To Frame It (https:&#x2F;&#x2F;texttoframe.it) as a midnight hustle. While I have a website for it, the actual service is a phone number (917-905-1015) you can text pics to and the recipient of those texts is an AI bot that automatically&#x2F;instantly frames those pics for you onto canvas, posters, puzzles, etc... And, from there, you can purchase what you like and have them shipped to your door in less than a week. The target market for this is individuals that want a simple, quick, frictionless way to create sentimental gifts - largely, guys like me lol on holidays like this one coming up. But, I digress ...<p>*The point I&#x27;m making:*\nThe entire system is automated with AI - the AI bot you text message (powered by ChatGPT), the AI bot you talk to when you call that same phone number (powered by Retellai.com &amp; ElevenLabs), the SEO-optimized blog posts (generated by a custom ChatGPT-powered AI workflow on Make.com - based off work by Nick Saraev), the ad campaigns (powered by AdWin from usestyle.ai), and more! And, I&#x27;m actually very proud of all of that. It allows me to run the entire thing as just one person. Not only does all of this allow me to keep the prices for framing the lowest in the market (with free shipping to boot), but it also allows me to focus on the core of the business: making quality products that people really like and find great for gifts and such. It also allows me to focus on how to make things quick and frictionless instead of worrying about writing the next sentence on a blog post, etc...<p>*So, my question:*\nI proudly have a disclaimer at the bottom of my blog posts highlighting that the blog posts are generated", "url": "https://news.ycombinator.com/item?id=42398505", "hn_url": "https://news.ycombinator.com/item?id=42398505", "score": 1, "num_comments": 4, "created_utc": 1734005509, "author": "ovoxo", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758657"}
{"source": "HackerNews", "title": "Ask HN: Do you use AI at work?", "text": "Do you use chat models like ChatGPT or Claude at work or in your industry?<p>I am a mid-level software engineer, and sometimes it feels like ChatGPT was a godsend, but I have spoken with people from other industries, like finance and sales, and they said that they could not find a way to use ChatGPT in their workflow.<p>Is using ChatGPT or other LLMs niche-specific?", "url": "https://news.ycombinator.com/item?id=39903388", "hn_url": "https://news.ycombinator.com/item?id=39903388", "score": 1, "num_comments": 3, "created_utc": 1712045253, "author": "zer0tokens", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758667"}
{"source": "HackerNews", "title": "Ask HN: What AI tools are you using in your daily workflows outside of ChatGPT?", "text": "", "url": "https://news.ycombinator.com/item?id=36662292", "hn_url": "https://news.ycombinator.com/item?id=36662292", "score": 23, "num_comments": 12, "created_utc": 1688965107, "author": "ankushio", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758672"}
{"source": "HackerNews", "title": "Show HN: Lotas \u2013 Cursor for RStudio", "text": "Hey HN! We\u2019re Jorge and Will from Lotas (<a href=\"https:&#x2F;&#x2F;www.lotas.ai&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.lotas.ai&#x2F;</a>), and we\u2019ve built an AI coding assistant into RStudio (think Cursor for RStudio).<p>RStudio is used by about 2 million data scientists and academics, but they currently lack a coding assistant within their IDE. Developers in other environments benefit from tools like Cursor and Windsurf, but R users don\u2019t have any equivalent tools to speed up their workflow. Since ~80% of R programmers prefer to use RStudio over other IDEs like VSCode to write R code, we figured a tool like this one could be quite useful.<p>Both of us were PhD students at Harvard. Jorge was in the biophysics program and Will was in the biostatistics program where most people used RStudio every day. We saw how integrated code assistants were taking off in other IDEs, but we noticed that the RStudio integrations were still lagging far behind. Many R users were copying and pasting code from ChatGPT to build their workflows, and this was clearly slow and fragile.<p>To bring the Cursor-like experience to RStudio users, we built Rao (<a href=\"https:&#x2F;&#x2F;www.lotas.ai&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.lotas.ai&#x2F;</a>): a fork of RStudio with an embedded AI assistant that is aware of the user\u2019s local context (both files and variable environment), can read and write files, can run code or commands, and can interpret textual or visual output. It works with any of the file formats already in RStudio (R, notebooks including RMDs and QMDs, Python, Stan, etc.), allowing R programmers to iteratively perform entire data analyses inside their preferred IDE.<p>Other AI data science tools are either (1) built on the web or in environments people don\u2019t already use, (2) are completely focused on python notebooks, or (3) are weak package-based assistants with limited functionality. Rao is exactly like the RStudio IDE that millions of data scientists already use", "url": "https://www.lotas.ai/", "hn_url": "https://news.ycombinator.com/item?id=44638510", "score": 82, "num_comments": 28, "created_utc": 1753121770, "author": "jorgeoguerra", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758678"}
{"source": "HackerNews", "title": "Ask HN: Will you be paying for ChatGPT+?", "text": "I was just offered the paid subscription yesterday for $20&#x2F;mo. I went ahead and signed up for this month just to see if bringing back the late-December speeds and uptime would feel compelling.<p>I&#x27;m still not really incorporating ChatGPT into my daily workflows at all, but I give it lots of &quot;for fun&quot; prompts all day. So, I am not confident I will stick with the subscription past a month, but I hope the payment pushes me to find more practical uses for it.<p>How about you?", "url": "https://news.ycombinator.com/item?id=34642912", "hn_url": "https://news.ycombinator.com/item?id=34642912", "score": 17, "num_comments": 53, "created_utc": 1675440218, "author": "SeanAnderson", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758688"}
{"source": "HackerNews", "title": "Ask HN: Best Set Up for AI Coding?", "text": "I&#x27;ve had a lot of success making simple and medium scale programs (web based and python) using Claude &amp; ChatGPT.<p>But my workflow is basically cut &amp; paste from the web console (chatgpt or claude.ai), execute it, copy errors back in with direction, repeat.<p>I often have to ask for it to provide the full code each time, which can take multiple replies. Or it will provide a bunch of small bits of code I have to manually try and go insert.<p>I&#x27;m looking for both better methodology using my existing tools, or introduction to other tools which certainly must exist that are better suited.<p>I&#x27;d like to have something that can modify the existing code base directly and doesn&#x27;t require me to cut and paste.<p>Ive bene using mostly HTML, PHP, Javascript &amp; Python.<p>Thanks in advance for the help!", "url": "https://news.ycombinator.com/item?id=42005590", "hn_url": "https://news.ycombinator.com/item?id=42005590", "score": 2, "num_comments": 1, "created_utc": 1730372997, "author": "ada1981", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758703"}
{"source": "HackerNews", "title": "Show HN: Use my powerful ChatGPT wrapper app for Free: Boost your productivity", "text": "Hey HN,<p>I got tired of copy-pasting&#x2F;retyping prompts on my phone for tasks like spell checking, comment generation, etc. So, I built an app to make it easier.<p>Introducing Gprompt, the ultimate ChatGPT prompt manager for iPhone:<p>Create and Reuse: Save and reuse prompt templates infinitely.\nCustomization: Adjust style and tone to fit your needs.\nDirect Sharing: Share tweets and LinkedIn posts directly from the app.\nSecure: Everything stays within your ChatGPT.<p>Transform your workflow:<p>-Translation prompt: Translator\n-Grammar prompt: Dictionary\n-Reply prompt: Social post comment generator\n-And much more...<p>Give it a try and let me know what you think!", "url": "https://robzapps.vercel.app/gprompt", "hn_url": "https://news.ycombinator.com/item?id=40947811", "score": 2, "num_comments": 1, "created_utc": 1720806619, "author": "vigneshvp", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758712"}
{"source": "HackerNews", "title": "I Built a Free AI Background Remover and Automated My SEO Workflow", "text": "I developed Ezpic (https:&#x2F;&#x2F;ezpic.fun), a free online background removal tool. To attract initial users through SEO-driven growth, I started writing blog content.\nWhen creating blog posts, I needed images with SEO-optimized alt tags. This required:<p>Uploading images to stable storage<p>Generating AI-powered alt descriptions<p>Converting links and alt descriptions into Markdown tags<p>While manageable for one blog post, this process became inefficient with multiple posts. So I developed a tool with ChatGPT to automate this workflow. Here&#x27;s the Python implementation:\npython\n\u8fd0\u884c\u590d\u5236\n1. # Generate filename\n2. import time\n3. import os\n4. import boto3\n5. from openai import OpenAI\n6. \n7. timestamp = int(time.time() * 1000)\n8. file_ext = os.path.splitext(file.filename)[1]\n9. file_name = f&#x27;uploads&#x2F;{timestamp}{file_ext}&#x27;\n10. \n11. # AWS S3 Configuration\n12. AWS_ACCESS_KEY_ID = &#x27;your_aws_access_key_id&#x27;\n13. AWS_SECRET_ACCESS_KEY = &#x27;your_aws_secret_access_key&#x27;\n14. AWS_REGION = &#x27;your_region&#x27;\n15. S3_BUCKET_NAME = &#x27;your_bucket_name&#x27;\n16. \n17. # Initialize S3 client\n18. s3_client = boto3.client(\n19.     &#x27;s3&#x27;,\n20.     aws_access_key_id=AWS_ACCESS_KEY_ID,\n21.     aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n22.     region_name=AWS_REGION\n23. )\n24. \n25. # Upload file\n26. s3_client.upload_file(file_name, S3_BUCKET_NAME, s3_object_key)\n27. \n28. # Build complete file URL\n29. file_url = f&#x27;https:&#x2F;&#x2F;DOMAIN&#x2F;{oss_file_name}&#x27;\n30. \n31. # OpenAI Configuration\n32. OPENAI_API_KEY = os.getenv(&#x27;OPENAI_API_KEY&#x27;)\n33. client = OpenAI(api_key=OPENAI_API_KEY)\n34. response = client.chat.completions.create(\n35.     model=&quot;gpt-4o-mini&quot;,\n36.     messages=[\n37.         {\n38.             &quot;role&quot;: &quot;user&quot;,\n39.             &quot;content&quot;: [\n40.                 {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;Please provide an SEO-friendly, concise description fo", "url": "https://news.ycombinator.com/item?id=42440906", "hn_url": "https://news.ycombinator.com/item?id=42440906", "score": 1, "num_comments": 0, "created_utc": 1734439384, "author": "ezpic", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758719"}
{"source": "HackerNews", "title": "Assessing the Utility of ChatGPT Throughout the Entire Clinical Workflow", "text": "", "url": "https://www.jmir.org/2023/1/e48659/PDF", "hn_url": "https://news.ycombinator.com/item?id=37532593", "score": 2, "num_comments": 0, "created_utc": 1694847160, "author": "Jimmc414", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758730"}
{"source": "HackerNews", "title": "Ask HN: Best AI Automation Platform", "text": "I&#x27;m holding AI First Workshops for Small to Mid-Sizes Companies. For lots of them the real value of AI comes with automation. Mostly Email -&gt; AI -&gt; Action<p>Thing is Make, Zapier, n8n - whenever I use them we waste more money on clicking around and what goes where then focusing on the overall business logic. The automation part of the workshop is about 2 to 3h. So what solutions out there for trigger based automation that os truly AI first (so an internal AI oder chatgpt can really create the workflow) and users can go from idea to running AI workflow in ~2h? Or is this a product that does not exist yet?", "url": "https://news.ycombinator.com/item?id=44761947", "hn_url": "https://news.ycombinator.com/item?id=44761947", "score": 3, "num_comments": 1, "created_utc": 1754079307, "author": "franze", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758735"}
{"source": "HackerNews", "title": "Looking for Resources on Agentic Coding for Game Development", "text": "Hey fellow devs,\nI\u2019ve been exploring Agentic Coding \u2014 the idea of giving AI agents goals rather than tasks \u2014 and I\u2019m curious if anyone here has applied this to actual game development, either in tooling or gameplay.\nThink Claude, GPT, or similar LLMs acting less like autocomplete and more like a junior engineer that plans, reasons, tests, and even iterates based on broader goals you give it.\nI\u2019m especially interested in:\nResources, tools, or frameworks built around this approach Examples of devs using LLMs as autonomous assistants in codebases Ideas for games that simulate or incorporate agentic thinking (e.g., AI NPCs, empire managers, agents with goal hierarchies) Thoughts on integrating this into build pipelines, editors, or scripting languages I\u2019m working on a sci-fi 4X game called Stellar Throne, and I\u2019m experimenting with agentic workflows using Claude and ChatGPT (I\u2019ve even built a custom CLAUDE.md spec to guide them). Would love to compare notes or find others deep in this rabbit hole.\nI\u2019ll compile anything useful from this thread into a blog post.\nThanks in advance!\n\u2013 MrPhil mrphilgames.com", "url": "https://news.ycombinator.com/item?id=44570125", "hn_url": "https://news.ycombinator.com/item?id=44570125", "score": 1, "num_comments": 0, "created_utc": 1752579744, "author": "MrPhilGames", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758742"}
{"source": "HackerNews", "title": "Ask HN: How are you incorporating ChatGPT/GPT-3/4 in your workflow?", "text": "I mean, e.g., a better interface that lets you use these models more easily? Or connecting them to other tools to get the most out of them?<p>I know Microsoft is gonna bring Copilot to their products. Is there something like that in other software or workflows that you&#x27;ve hacked together and enjoy?", "url": "https://news.ycombinator.com/item?id=35461252", "hn_url": "https://news.ycombinator.com/item?id=35461252", "score": 11, "num_comments": 4, "created_utc": 1680733485, "author": "behnamoh", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758751"}
{"source": "HackerNews", "title": "Show HN: Pitched a VC for 30min before realizing they invested in a competitor", "text": "Hey HN,<p>I pitched an investor for 30 minutes before realizing they&#x27;d already passed on a similar company in their portfolio.<p>That moment broke me. I&#x27;d wasted both our time because I didn&#x27;t do basic research.<p>So I built Briefing AI: Paste any calendar invite and Get an Intelligence-style dossier on attendees in 30 seconds.<p>THE WORKFLOW:<p>You have a meeting in 10 minutes. You know nothing about the attendees.<p>Before:<p><pre><code>  \u2022 Open LinkedIn, search &quot;Sarah Chen Sequoia&quot;\n  \u2022 Skim profile, open 5 tabs\n  \u2022 Google her recent activity\n  \u2022 Try to remember talking points\n  \u2022 Show up flustered\n  \u2022 Total time: 15-20 minutes (if you even do it)\n</code></pre>\nAfter:<p><pre><code>  \u2022 Paste calendar invite into Briefing AI\n  \u2022 Get: Executive summary, attendee backgrounds, company context, talking points, red flags\n  \u2022 Walk in prepared\n  \u2022 Total time: 30 seconds\n</code></pre>\nTHE TECH:<p><pre><code>  \u2022 Next.js 15 + Cloudflare Pages (serverless)\n  \u2022 Brave Search API (real company&#x2F;attendee data, not just AI hallucinations)\n  \u2022 GPT-4 (parsing + generation)\n  \u2022 Device fingerprinting (1 free briefing, then $49 LTD or $19&#x2F;month)\n</code></pre>\nLaunched Friday. Made 2 sales. Learning fast.<p>&quot;BUT CAN&#x27;T I JUST USE CHATGPT?&quot;<p>Yes. But:<p><pre><code>  \u2022 ChatGPT = 8-10 prompts, 10 minutes (&quot;extract attendees&quot; \u2192 &quot;who is Sarah?&quot; \u2192 &quot;what should I ask?&quot;)\n  \u2022 Briefing AI = 1 paste, 30 seconds\n  \u2022 ChatGPT = conversation disappears\n  \u2022 Briefing AI = saved dashboard, searchable history\n</code></pre>\nI&#x27;m not competing with ChatGPT. I&#x27;m making one specific workflow 10x faster.<p>WHAT I LEARNED (2 sales in 3 days):<p>The problem is real (everyone wings meetings), but I have zero distribution. 80 website visits, 2.5% conversion. Product works. Distribution doesn&#x27;t.<p>So I&#x27;m asking HN:<p><pre><code>  \u2022 Is this genuinely useful, or am I solving a fake problem?\n  \u2022 Would you pay $49 lifetime ", "url": "https://getbriefing.io/", "hn_url": "https://news.ycombinator.com/item?id=45656834", "score": 1, "num_comments": 1, "created_utc": 1761059571, "author": "uchibeke", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758766"}
{"source": "HackerNews", "title": "Ask HN: How are you using LLMs?", "text": "I&#x27;ve just got back from a nice long period off work to become a parent, and it seems like I&#x27;ve fallen behind in what the SOTA is with LLMs and uses. Let&#x27;s say about I&#x27;ve got about a year to catch up on.<p>My workflow was to use Claude&#x2F;ChatGPT for security research assistance, basically a Google step-in, and Cursor in manual mode to generate and modify code. Wasn&#x27;t really too fond of agent mode in Cursor but that now seems like the standard, that or Claude Code generating heaps of code?<p>So what does your workflow look like in your day-to-day? Anything other than Cursor&#x2F;CC + some LLM provider?", "url": "https://news.ycombinator.com/item?id=45358699", "hn_url": "https://news.ycombinator.com/item?id=45358699", "score": 1, "num_comments": 0, "created_utc": 1758711657, "author": "0x303", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758778"}
{"source": "HackerNews", "title": "Maximizing Productivity with ChatGPT: 11 Ways AI Can Streamline Your Workflow", "text": "", "url": "https://twitter.com/svpino/status/1611357154514186241", "hn_url": "https://news.ycombinator.com/item?id=34298800", "score": 3, "num_comments": 0, "created_utc": 1673183316, "author": "baptiste313", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758784"}
{"source": "HackerNews", "title": "Show HN: ChatGDB \u2013 GPT-Powered GDB Assistant", "text": "ChatGDB is a tool designed to superpower your debugging experience with GDB, a debugger for compiled languages. Use it to accelerate your debugging workflow by leveraging the power of ChatGPT to assist you while using GDB!<p>It allows you to explain in natural language what you want to do, and then automatically execute the relevant command. Optionally, you can ask ChatGPT to explain the command it just ran or even pass in any question for it to answer. Focus on what&#x27;s important - figuring out that nasty bug instead of chasing down GDB commands at the tip of your tongue.<p>See it here: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;pgosar&#x2F;ChatGDB\">https:&#x2F;&#x2F;github.com&#x2F;pgosar&#x2F;ChatGDB</a>", "url": "https://github.com/pgosar/ChatGDB", "hn_url": "https://news.ycombinator.com/item?id=35483933", "score": 189, "num_comments": 54, "created_utc": 1680886595, "author": "pgosar0514", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758790"}
{"source": "HackerNews", "title": "Show HN: A Unique User-in-the-Loop Agent for Investment Research", "text": "Hey HN,<p>I am a first time founder working on Vector -- an agentic platform for investment research and analysis. Looking for feedback on the public beta that was launched, specifically around the unique philosophy behind this product. Which usually ends up either really gamechanging or just dumb -- I recognize this and hence feel the need to try and validate things as early as possible.<p>This product was born from personal needs and frustration with existing platforms and tools. I am a retail investor myself managing a significant personal portfolio. Even though I only rebalance quarterly, it takes significant time and effort to keep up with emerging risks to my portfolio and even more time to research and develop conviction around new ideas for diversification. Seeking Alpha is a chore to go through with too much generic content, inconsistent quality and noise. ChatGPT and Perplexity Finance lack a decent workflow (too chatbot centric). Deep research might seem great at first, but the lack of control and verbosity becomes a pain very quickly.<p>Vector is designed around two core theses that we believe differentiate it meaningfully from existing solutions<p>1) User-in-the-loop. We recognize that AI agents still limited in reasoning capabilities and require guidance for many complex tasks. Secondly, we also believe that investment research is an open ended and rather subjective task. Useful research processes(ones that help consumers achieve&#x2F;overturn convictions)require the means to let the consumer change&#x2F;challenge the methodology and also the assumptions made.<p>2) Embed agents into well tested workflow, not force a chatbot on users. Many AI&#x2F;LLM powered products out there today are chatbot first for some reason. Some claim that this is because natural language is the most powerful HCI given the capabilities of LLMs today. It is true in some instances but false for many others. For the problem we are tackling, a chatbot is not a natural workflow fo", "url": "https://vector.deepinsightlabs.ai/login", "hn_url": "https://news.ycombinator.com/item?id=44695841", "score": 3, "num_comments": 2, "created_utc": 1753552474, "author": "nlpnerd", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758799"}
{"source": "HackerNews", "title": "Show HN: Sylvio AI \u2013 Your Smartest Quiet Teammate", "text": "*Sylvio AI* is an intelligent, all-in-one developer companion app that brings together powerful AI tools to streamline software development, content creation, debugging, documentation, and learning\u2014all in one place. Whether you&#x27;re a solo indie hacker, student, or experienced developer, Sylvio AI helps you ideate, build, and polish your projects faster and smarter with zero setup or cost.<p>---<p>##   1. *Who is the App For?*<p>* *Developers* (from beginners to experienced engineers)\n* *Students* learning programming and computer science\n* *Startup founders &#x2F; indie hackers*\n* *Technical writers &#x2F; educators*\n* *Freelancers &#x2F; dev content creators*\n* *Product managers &amp; DevOps professionals* (for planning and documenting)<p>---<p>##  2. *What Are Its Benefits?*<p>* Saves *time* by automating repetitive dev tasks\n* Helps you *learn* and understand concepts (e.g., regex, errors, snippets)\n* Boosts *productivity* through centralized tools\n* Improves *code quality* and project documentation\n* Simplifies *project planning and communication*\n* Offers *one-click generation* for common dev tasks like README.md, changelogs, boilerplate, etc.\n* 100% *free and ready-to-use*<p>---<p>##  3. *What Problem Does It Solve, and How?*<p>###  Problem:<p>Developers constantly jump between ChatGPT, Stack Overflow, GitHub, code snippet sites, name generators, planning boards, and more\u2014fragmented workflows slow down productivity and creativity.<p>###  Solution:<p>Sylvio AI *centralizes all essential developer tools in one smart platform*, giving you focused, pre-built tools tailored specifically for developer workflows.<p>Examples:<p>* Instead of prompting ChatGPT 10 different times, generate a README, app name, changelog, and boilerplate instantly from your project description.\n* Copy-paste an error message, and Sylvio explains it and offers real-time fixes.\n* Convert code across languages (e.g., JS \u2192 Python) with one click.\n* Create flashcards and summaries from tech ", "url": "https://www.sylvioai.xyz", "hn_url": "https://news.ycombinator.com/item?id=44816926", "score": 3, "num_comments": 1, "created_utc": 1754510257, "author": "PraiseAsuquo", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758808"}
{"source": "HackerNews", "title": "Show HN: Tool to upload GitHub repo to ChatGPT", "text": "Hi, I needed a fun excercise to build and I noticed in my development workflow that I was constantly giving ChatGPT new copies of my code by copy-pasting individual files into the chat. I also noticed that I couldn&#x27;t upload my project into ChatGPT, nevermind giving it updated files.<p>I decided to quickly make this tool to programmatically upload my GitHub repo to ChatGPT and query it.<p>I know there may be other ways to do this such as GitHub Copilot, but I wanted an exercise to build and I also heard GPT 4 gives better responses than Copilot.<p>If there&#x27;s a better option that isn&#x27;t GitHub Copilot then share it below and I will probably use it. I also may give Copilot a go.<p>You can run it locally by visiting the GitHub below.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;erictrimbs&#x2F;coding-assistant\">https:&#x2F;&#x2F;github.com&#x2F;erictrimbs&#x2F;coding-assistant</a>", "url": "https://www.youtube.com/watch?v=PLFR14-ZTC4", "hn_url": "https://news.ycombinator.com/item?id=41047946", "score": 1, "num_comments": 0, "created_utc": 1721752357, "author": "ETrimbs", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758827"}
{"source": "HackerNews", "title": "Show HN: I built a non-linear UI for ChatGPT", "text": "Hi HN,<p>I built this out of frustration of the evergrowing list of AI models and features to try and to fit my workflow.<p>The visual approach clicks for me so i went with it, it provides more freedom and control of the outcome, because predictable results and increased productivity is what I\u2019m after when using conversational AI.<p>The app is packed with features, my most used are prompt library, voice input and text search, narration is useful too.<p>The app is local-first and works right in the browser, no sign up needed and it&#x27;s absolutely free to try.<p>BYOAK \u2013 bring your own API Keys.<p>Let me know what you think, any feedback is appreciated!", "url": "https://www.grafychat.com", "hn_url": "https://news.ycombinator.com/item?id=40300126", "score": 459, "num_comments": 130, "created_utc": 1715186472, "author": "setnone", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758835"}
{"source": "HackerNews", "title": "Show HN: SiteGPT \u2013 Create ChatGPT-like chatbots trained on your website content", "text": "Hello everyone,<p>I am the founder of a blogging platform called Feather.so.<p>People can sign up and create their own blogs using Feather.<p>Now, with OpenAI releasing their API, they made using AI so accessible for someone like me. So I wanted to add a chatbot functionality to my customer blogs. Basically, I wanted to automatically create a chatbot for each of my customer blogs. That chatbot will be trained on the content on their blog.<p>When I set out to do this using Open AI, I thought I could do this for every website, not just for my customer blogs.<p>So I ended up creating an entirely new product called SiteGPT.ai so that it can be used on any website.<p>The workflow works like this. People login the platform, they enter their website url, and click on a button to start training. Then I start creating a chatbot and train the chatbot will all the content on the website that the user enters.<p>That chatbot now knows everything about that website. It can answer any questions related to that website.<p>I have also added a demo chatbot at the bottom right of the sitegpt.ai website. That chatbot is trained on the content of SiteGPT.ai. So it can answer any questions related to its own website.<p>Please try it out and let me know if you have any feedback. I am also happy to take any other technical questions you may have.<p>Thanks.", "url": "https://sitegpt.ai", "hn_url": "https://news.ycombinator.com/item?id=35404852", "score": 118, "num_comments": 96, "created_utc": 1680388575, "author": "pbteja1998", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758842"}
{"source": "HackerNews", "title": "Show HN: Open-source alternative to ChatGPT Agents for browsing", "text": "Hey HN,<p>We are Winston, Edward, and James, and we built Meka Agent, an open-source framework that lets vision-based LLMs execute tasks directly on a computer, just like a person would.<p>Backstory:<p>In the last few months, we&#x27;ve been building computer-use agents that have been used by various teams for QA testing, but realized that the underlying browsing frameworks aren&#x27;t quite good enough yet.<p>As such, we&#x27;ve been working on a browsing agent.<p>We achieved 72.7% on WebArena compared to the previous state of the art set by OpenAI&#x27;s new ChatGPT agent at 65.4%. You can read more about it here: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;trymeka&#x2F;webarena_evals\">https:&#x2F;&#x2F;github.com&#x2F;trymeka&#x2F;webarena_evals</a>.<p>Today, we are open sourcing Meka, our state of the art agent, to allow anyone to build their own powerful, vision-based agents from scratch. We provide the groundwork for the hard parts, so you don&#x27;t have to:<p>* True vision-based control: Meka doesn&#x27;t just read HTML. It looks at the screen, identifies interactive elements, and decides where to click, type, and scroll.<p>* Full computer access: It&#x27;s not sandboxed in a browser. Meka operates with OS-level controls, allowing it to handle system dialogues, file uploads, and other interactions that browser-only automation tools can&#x27;t.<p>* Extensible by design: We&#x27;ve made it easy to plug in your own LLMs and computer providers.<p>* State-of-the-art performance: 72.7% on WebArena<p>Our goal is to enable developers to create repeatable, robust tasks on any computer just by prompting an agent, without worrying about the implementation details.<p>We\u2019d love to get your feedback on how this tool could fit into your automation workflows. Try it out and let us know what you think.<p>You can find the repo on GitHub and get started quickly with our hosted platform, <a href=\"https:&#x2F;&#x2F;app.withmeka.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;app.with", "url": "https://github.com/trymeka/agent", "hn_url": "https://news.ycombinator.com/item?id=44734471", "score": 104, "num_comments": 23, "created_utc": 1753884696, "author": "ElasticBottle", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758850"}
{"source": "HackerNews", "title": "My Workflow Is 70% AI, 20% Copy-Paste, 10% Panic. What's Yours?", "text": "Being an analyst I need to research about the market and work accordingly. With the help of ChatGPT, perplexity and Gemini, I get done 70% of my research work. The rest of the 30% is just pure brainstorming. Then if I need some graphics then I use Canva for designing them. I get the images from them. Sometimes, I create ppts too using it. If I need any videos then i usually use tool like fliki, Lunabloom Ai or invideo to generate video. These tools give me good quality AI generated videos. Then nowadays, AI is also available on social medias. It makes the job easier for me. So basically, Most of my work is completed by AI. The one thing I need to do properly is to give them proper instructions. How do you go about it?", "url": "https://news.ycombinator.com/item?id=45195543", "hn_url": "https://news.ycombinator.com/item?id=45195543", "score": 33, "num_comments": 67, "created_utc": 1757499105, "author": "jamessmithe", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758861"}
{"source": "HackerNews", "title": "Show HN: Fast-agent \u2013 Compose MCP enabled Agents and Workflows in minutes", "text": "Hello, HN.<p>I&#x27;ve created fast-agent to make building my own products easier - and remove the friction between defining Prompts, MCP Servers and their composition. It uses a simple, declarative style that&#x27;s easy to work with and source control - with inbuilt support for the patterns in the Building Effective Agents paper.<p>Because you can &quot;warm-up&quot; and interact with Agents before, during or after the workflows, it&#x27;s easy to diagnose and tune Agent prompts and behaviour for later runs. Being able to set these workflows up makes LLM Context Management and Tool Selection a lot easier and can vastly improve output quality for little effort.<p>For MCP Server developers you can see how different models interpret tool descriptions. There&#x27;s also MCP Roots support, and it comes bundled with a ChatGPT style data-analysis tool (`fast-agent bootstrap data-analysis`) as one of the demonstrations.<p>One of the thing I am most looking forward to is combining MCP data retrieval with Anthropic&#x27;s Citations API - I think that&#x27;s going to be an incredibly important feature in a lot of scenarios.<p>It&#x27;s been forked from, and and builds upon Sarmad Qadri&#x27;s mcp-agent framework, and we&#x27;re collaborating to keep the projects in-sync.<p>Anyway, I&#x27;d love to hear your thoughts and feedback on this project, and eager to hear from potential users, contributors and collaborators.", "url": "https://github.com/evalstate/fast-agent", "hn_url": "https://news.ycombinator.com/item?id=43282093", "score": 29, "num_comments": 3, "created_utc": 1741278860, "author": "evalstate", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758867"}
{"source": "HackerNews", "title": "Computational Graphs in AI [ChatGPT Pulse] \u2013 We Are Better", "text": "", "url": "https://www.hopit.ai/stories?category=software_engineering_first_principles&slug=how-computation-graphs-optimize-deep-learning-workflows-2025-09-26-57a3b&source=HOME_STORY_CLICK", "hn_url": "https://news.ycombinator.com/item?id=45387563", "score": 8, "num_comments": 1, "created_utc": 1758900218, "author": "ArchieIndian", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758886"}
{"source": "HackerNews", "title": "ChatGPT is 1yo now. Which LLM framework(s) do you use in production and why?", "text": "I&#x27;ve come across many LLM frameworks: Langchain, LlamaIndex, LMQL, guidance, Marvin, Instructor, etc. There&#x27;s a lot of overlap between them and I don&#x27;t know if any of them actually adds a value to LLM workflows in a way that&#x27;s maintainable and robust. So far, I&#x27;ve been able to just build my own little libraries to use in some LLM applications (no RAG), but as I consider the more recent advancements in the field (guaranteed function calling, better RAG, agents and tool use, etc.), I wonder if using one of these frameworks would be a better approach compared to building everything on my own.<p>I appreciate your thoughts and comments on this!", "url": "https://news.ycombinator.com/item?id=38518890", "hn_url": "https://news.ycombinator.com/item?id=38518890", "score": 8, "num_comments": 0, "created_utc": 1701705635, "author": "behnamoh", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758892"}
{"source": "HackerNews", "title": "Show HN: ChatGPT taught me how to code \u2013 I made a daily movie song guessing game", "text": "Backstory: I&#x27;m a product designer who&#x27;s mostly worked for startups and now big tech, and I haven&#x27;t really touched html&#x2F;css for nearly a decade. I&#x27;ve worked closely with engineers my entire career but never really rolled the sleeves up and dived into a scripting language. I&#x27;d seen some engineers playing around with CodeGPT over a year ago when it launched\u2013we huddled around a screen and tried to decide how quickly our jobs would be replaced by this new technology. At the time, we weren\u2019t in any real danger, but I caught a glimpse of how well it understood prompts and stubbed out large amounts of code.<p>For the past four or five years, I&#x27;ve played a hacky trivia game with family and friends where I play a song, and they have to guess the movie that features the song; Guess the Needle Drop. After many passionate debates and over-the-top celebrations fueled by my generation\u2019s nostalgia for popular classic songs and films, people often told me that I needed to \u201cbuild an app for this.\u201d<p>I started doodling in Figma before quickly starting to build the website in Node, and then read somewhere that it&#x27;s a better approach to learn vanilla javascript before trying to benefit from frameworks like React, etc. So I started again with a static vanilla website and, piece by piece, built out each chunk of functionality I\u2019d envisioned. My mind was consistently blown at how helpful ChatGPT was\u2013far beyond my lofty expectations, even with all the AI hype. It was like having a 24&#x2F;7 personal tutor for free. I rarely had to google console errors hoping that a Stack Overflow discussion catered to my exact scenario. With enough information, ChatGPT always knew what was wrong and explained in terms I could understand.<p>The workflow went like this: I would describe the desired user experience, parse the code GPT suggested, copy it to my editor, and paste back any errors I came across along the way. The errors were abundant at the beginning, but I ", "url": "https://www.needledrop.me", "hn_url": "https://news.ycombinator.com/item?id=39550019", "score": 7, "num_comments": 5, "created_utc": 1709218250, "author": "wernah", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758902"}
{"source": "HackerNews", "title": "Show HN: Lexeme \u2013 open-source ChatGPT text editor", "text": "Everyone&#x27;s favorite ChatGPT tool is the one they created themselves!  Here&#x27;s mine, a text editor for power users of ChatGPT, inspired by the flexibility of SQL workbench. I despise constantly switching between ChatGPT and VSCode just to copy and paste text for further editing.<p>Lexeme is my attempt to solve workflow issues like this, along with a few other improvements. You can easily start a chat with ChatGPT by highlighting any text. Lexeme allows you to create multiple chats within the same document, keeping each chat context separate to support an iterative writing process with the help of ChatGPT.<p>I have been using it almost daily for the past 4-5 months and have added a couple of features to fit my specific use cases. I&#x27;m not sure how useful this will be to others, but it&#x27;s there lol<p>demo: <a href=\"https:&#x2F;&#x2F;pagebrain.ai&#x2F;lexeme&#x2F;\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;pagebrain.ai&#x2F;lexeme&#x2F;</a><p>code: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;pagebrain&#x2F;lexeme\">https:&#x2F;&#x2F;github.com&#x2F;pagebrain&#x2F;lexeme</a>", "url": "https://pagebrain.ai/lexeme/", "hn_url": "https://news.ycombinator.com/item?id=38101251", "score": 7, "num_comments": 5, "created_utc": 1698858126, "author": "kornesh", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758913"}
{"source": "HackerNews", "title": "Show HN: Olli (YC W22) \u2013 ChatGPT for analysis on relational databases", "text": "Hi HN, we\u2019re the cofounders of Olli: ChatGPT for relational databases. Our software helps businesses to incorporate AI in their data workflows so that they can answer business questions faster and easily create dashboards for any use case.<p>You can find us at <a href=\"https:&#x2F;&#x2F;www.olli.ai\">https:&#x2F;&#x2F;www.olli.ai</a> and try the product out for free. Our demo video is here: <a href=\"https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;51a7d7b4b9654218b3576c6655c0993d\" rel=\"nofollow\">https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;51a7d7b4b9654218b3576c6655c0993d</a>.<p>We&#x27;re focused on providing companies with all the components needed to make these models work effectively &#x2F; securely for the business intelligence workflow. This means that we offer an intuitive UI for non-technical users, connections to the most popular relational databases and warehouses, on-prem deployment options, and team features.<p>This space is evolving daily and we\u2019re continuing to find ways to improve the product, so we would greatly appreciate any feedback that you have! Thanks for reading.", "url": "https://olli.ai/", "hn_url": "https://news.ycombinator.com/item?id=35775172", "score": 7, "num_comments": 0, "created_utc": 1682958567, "author": "seandoh", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758920"}
{"source": "HackerNews", "title": "Ask HN: Whats your best workflows to draft legal agreements without lawyers?", "text": "I just got an insane bill from a lawyer for drafting an agreement. \nI was wondering if some of you have a great workflow for drafting legal agreements with AI that are good enough to have a lawyer just review it?\nMy background is CS, so it&#x27;s hard judge myself and I feel ChatGPT doesn&#x27;t give enough details.", "url": "https://news.ycombinator.com/item?id=44729108", "hn_url": "https://news.ycombinator.com/item?id=44729108", "score": 6, "num_comments": 14, "created_utc": 1753828967, "author": "philippb", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758928"}
{"source": "HackerNews", "title": "Show HN: Peneterrer \u2013 The ChatGPT for Website Security Testing", "text": "Hi HN! I am a 14-year-old building Peneterrer. It is a tool for web and solo developers to check their website&#x27;s security with easy-to-read reports and custom testing workflows.<p>The Main objective of Peneterrer is to make the lives of web developers easy, and it does this by allowing web developers to test their websites by simply using words.<p>Until now I have spent around 3 months creating this and would love for you all to try it!", "url": "https://peneterrer.com", "hn_url": "https://news.ycombinator.com/item?id=40739807", "score": 6, "num_comments": 4, "created_utc": 1718897249, "author": "Adeeb0123", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758935"}
{"source": "HackerNews", "title": "Tell HN: ChatGPT has become terrible for academic research", "text": "I have a paid subscription to ChatGPT. Mostly I use it for Python coding as it is not my primary language. Occasionally, I also use it to ask research findings so that I can build my search on Google Scholar from there. ChatGPT uses Bing to search for the research articles and then summarize them. I just want to share that this is a terrible workflow. It is like trying to drive a Model S while it&#x27;s being carried by a donkey cart. If it is not clear, Bing is the donkey cart here.<p>For example, here is the response to a search query I gave to ChatGPT earlier today:<p>*For specific academic research findings, you would typically look into scholarly articles and research papers from economic and business journals. Common sources for such literature include the Journal of Finance, the Journal of Financial Economics, and the American Economic Review. Unfortunately, I cannot cite specific articles at this moment due to technical limitations, but these journals and their respective databases would be excellent places to start your research.*<p>In contrast, Claude.ai does a great job of listing relevant articles.", "url": "https://news.ycombinator.com/item?id=39150065", "hn_url": "https://news.ycombinator.com/item?id=39150065", "score": 6, "num_comments": 2, "created_utc": 1706310433, "author": "malshe", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758949"}
{"source": "HackerNews", "title": "Show HN: Typemagic \u2013 ChatGPT you can teach", "text": "Hey HN! I&#x27;m Karthik &amp; have been working on Typemagic (<a href=\"https:&#x2F;&#x2F;typemagic.com\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;typemagic.com</a>): a ChatGPT client that saves your prompts, and applies them when needed based on your chat.<p>The Problem:\nSince it came out, I&#x27;ve been using ChatGPT for various tasks, such as coding, generating database queries, reviewing my writing, and learning new things. Initially, I found myself constantly managing useful prompts in a Notion doc. I&#x27;d either paste a prompt from Notion to provide the right context or sift through my chat history to locate that context.<p>Some examples of snippets I frequently used include:\n- A detailed summary of my Tech stack.\n- Movie and book preferences (for suggestions).\n- My database schema (so that it could write queries).\n- Writing guidelines to follow when reviewing my writing.<p>This workflow was fine for 3 prompts, but sucked for 10. So I set out to build a better way.<p>Typemagic automatically searches for the best prompts in your library, applying them when needed based on your chat. Once you save a prompt, you (hopefully!) don&#x27;t have to worry about applying it manually - Typemagic takes care of it. While there&#x27;s definitely room for improvement, this approach has been more effective than manually searching and pasting the right prompts for me.<p>I&#x27;d greatly appreciate any feedback you have, especially critical feedback :).<p>The Journey:\nThis is the second iteration of the product. In the first version, you could create ChatGPT agents to chat with. But before asking what you wanted, you had to choose the right agent to chat with. Needing to make this decision every time you wanted to switch context was too much friction.<p>I realized my design approach was outdated. With AI, we have the opportunity to offload more decision making from users&#x27; minds onto AI. The right balance is one in which users act more as managers: approving &#x2F; reje", "url": "https://www.typemagic.com/", "hn_url": "https://news.ycombinator.com/item?id=36374497", "score": 5, "num_comments": 4, "created_utc": 1687035341, "author": "koopuluri", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758957"}
{"source": "HackerNews", "title": "Show HN: I made an extension for ChatGPT that lets you track changes", "text": "I\u2019ve been using this for my own workflow and friends suggested I share it with them so I quickly threw together my first chrome extension! As an ex-editor, I think chatGPT is overlooked as an editor with everyone jumping straight into writing. Editing is essentially giving it as comprehensive a writing prompt as possible. Playing with the actual prompt also gets you a wide range of different results that grammarly&#x2F;other apps cant really do. The x% has been changed tool was the first thing I built to see how intrusive chatGPT&#x27;s editing was at a glance. My biggest struggle was trying to limit chatGPT from doing too much.<p>Some example prompts<p>Proofread this but only fix grammar: (10% change)<p>Proofread this: (20-30% change)<p>Proofread this, lightly improving clarity and flow: (30-40% change)<p>Proofread this, improving clarity and flow: (30-50% change)<p>Proofread this, significantly improving clarity and flow: (40-60% change)<p>Proofread these 5 bullet points: (you sometimes have to specify this otherwise it turns it into a paragraph)<p>Proofread these 4 bullet points from my CV, keep it in CV language: (helps prevent it from adding personal pronouns)", "url": "https://www.editgpt.app/", "hn_url": "https://news.ycombinator.com/item?id=34831098", "score": 5, "num_comments": 0, "created_utc": 1676611337, "author": "shuafeiwang", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758967"}
{"source": "HackerNews", "title": "Show HN: Open-source UI components for apps that run inside ChatGPT", "text": "800M people use ChatGPT and Claude weekly. Right now they get text responses. Soon they&#x27;ll get real interfaces: product cards, blog posts, booking flows, payment screens rendered directly in the conversation.<p>We built an open-source component library for this. Install any block with one command and customize it to your brand.<p>If you&#x27;re building MCP servers or experimenting with AI-native apps, this might save you time.<p>Are you building apps for AI assistants? Would love to hear what&#x27;s missing in your workflow.", "url": "https://ui.manifest.build", "hn_url": "https://news.ycombinator.com/item?id=46234654", "score": 4, "num_comments": 0, "created_utc": 1765475620, "author": "stosssik", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.758975"}
{"source": "HackerNews", "title": "Show HN: Non-Linear Prompt Workflow Builder", "text": "I found ChatGPT to be limiting if you&#x27;re working with long chains of prompts.<p>So I build this tool to work to have more control.\nThe prompt nodes can only see direct connections.<p>I&#x27;ve been using this tool mainly for writing articles, but I&#x27;m wondering what other use-cases this could be relevant for.", "url": "https://aiflowchat.com/", "hn_url": "https://news.ycombinator.com/item?id=44158907", "score": 4, "num_comments": 0, "created_utc": 1748872577, "author": "qwertyu_alex", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.758995"}
{"source": "HackerNews", "title": "Show HN: ChatGPT You Can Teach", "text": "Hey HN! I&#x27;m Karthik &amp; have been working on Typemagic (https:&#x2F;&#x2F;typemagic.com): a ChatGPT client that saves your prompts, and applies them when needed based on your chat.<p>The Problem:\nSince it came out, I&#x27;ve been using ChatGPT for various tasks, such as coding, generating database queries, reviewing my writing, and learning new things. Initially, I found myself constantly managing useful prompts in a Notion doc. I&#x27;d either paste a prompt from Notion to provide the right context or sift through my chat history to locate that context.<p>Some examples of snippets I frequently used include:\n- A detailed summary of my Tech stack.\n- Movie and book preferences (for suggestions).\n- My database schema (so that it could write queries).\n- Writing guidelines to follow when reviewing my writing.<p>This workflow was fine for 3 prompts, but sucked for 10. So I set out to build a better way.<p>Typemagic automatically searches for the best prompts in your library, applying them when needed based on your chat. Once you save your a prompt, you (hopefully!) don&#x27;t have to worry about applying it manually - Typemagic takes care of it. While there&#x27;s definitely room for improvement, this approach has been more effective than manually searching and pasting the right prompts for me.<p>I&#x27;d greatly appreciate any feedback you have, especially critical feedback :).<p>The Journey:\nThis is the second iteration of the product. In the first version, you could create ChatGPT agents to chat with. But before asking what you wanted, you had to choose the right agent to chat with. Needing to make this decision every time you wanted to switch context was too much friction.<p>I realized my design approach was outdated. With AI, we have the opportunity to offload more decision making from users&#x27; minds onto AI. The right balance is one in which users act more as managers: approving &#x2F; rejecting proposals, vs. actually, outright, deciding. As AI becomes mo", "url": "https://news.ycombinator.com/item?id=36373971", "hn_url": "https://news.ycombinator.com/item?id=36373971", "score": 4, "num_comments": 0, "created_utc": 1687031924, "author": "koopuluri", "ai_tool": "ChatGPT", "scraped_at": "2025-12-17T17:19:02.759001"}
{"source": "HackerNews", "title": "I rescued 42 ChatGPT conversations from digital lock-in (technical guide)", "text": "# I Rescued 42 ChatGPT Conversations from Digital Lock-in<p>## The Problem\nChatGPT Teams has *no bulk export feature.* After months of documenting my IoT startup, I had 42 critical files trapped: technical specs, business strategies, project handoffs. OpenAI&#x27;s only solution? Manual copy-paste. 7+ hours of work.<p>You&#x27;re renting access to your own IP.<p>## The Solution: Claude + Notion Automation<p>I found a workflow that cuts this to 40 minutes. Here&#x27;s the exact process:<p>*Prerequisites:*\n- Claude Pro (Notion integration required)\n- Export ChatGPT conversations to .md files\n- Save to desktop folder: `&#x2F;Desktop&#x2F;ChatGPT-Export&#x2F;`<p>*Step 1: Initial Command*\n```\nI have markdown documents from ChatGPT chats. Create a master page called &quot;ChatGPT Chats&quot; and put all the md files there as pages. Then create a CONTENTS PAGE and index page. Files are here: &#x27;&#x2F;Users&#x2F;[username]&#x2F;Desktop&#x2F;ChatGPT-Export&#x27;\n```<p>*Step 2: Handle Rate Limits* (This WILL happen)\nAfter ~10 imports, you&#x27;ll hit &quot;Tool execution failed&quot; errors.<p>*Fix:* Toggle Notion OFF&#x2F;ON in Claude&#x27;s tools menu, then:\n```\nI just cycled the notion access. Try again for the remaining files.\n```<p>Repeat this 3-4 times until complete.<p>## What You Get\n- Master collection page with stats\n- Contents page (organized by category)  \n- Index page (alphabetical)\n- Individual pages for all documents\n- Full navigation and search<p>*Performance:*\n- Time: 40 minutes vs 7+ hours manual\n- Success rate: 100% with persistence  \n- Documents: 42&#x2F;42 imported\n- Pages created: 45 total<p>## Technical Reality\nThis requires babysitting. You&#x27;ll toggle Notion access multiple times and run retry commands. But it works.<p>*Common errors:*\n- &quot;Tool execution failed&quot; \u2192 Toggle Notion off&#x2F;on\n- &quot;Connection timeout&quot; \u2192 Refresh, retry\n- Empty pages \u2192 Content added in next batch<p>## The Bigger Picture\nThis exposes critical AI platfo", "url": "https://news.ycombinator.com/item?id=45033237", "hn_url": "https://news.ycombinator.com/item?id=45033237", "score": 3, "num_comments": 3, "created_utc": 1756248078, "author": "Andwardo", "ai_tool": "Claude", "scraped_at": "2025-12-17T17:19:02.759022"}
{"source": "HackerNews", "title": "Ask HN: By what percentage has AI changed your output as a software engineer?", "text": "Compared to the era before AI coding tools (say, ~2 years ago), if you had to put a number on it, how much has your productivity as a SWE changed?<p>I think about this a lot; am keen to hear what others&#x27; perceptions are. For me; the short answer: about 2x (i.e. 100% faster than pre LLMs). Long answer:<p>When I thoroughly understand the domain (i.e. business logic and real world problem I&#x27;m solving), and am familiar with the tech stack, I&#x27;m about ~10x faster for the same or better code quality.<p>When I don&#x27;t understand the domain, prompts will be ambiguous or inadequate, the LLM will guess, it will do a month&#x27;s work in a day, but I&#x27;ll spend the next 3 weeks refactoring and realising how trash the code was, due to how trash the prompt was. All in all, it&#x27;s probably still faster than pre AI, but can give a demoralising psychological phenomena where you <i>think</i> something&#x27;s nearly completed only to spend weeks debugging it, refactoring, and often tossing it away and starting over.<p>In an unfamiliar tech stack, I can&#x27;t always spot obvious mistakes (mistakes caused by the AI or the prompt), so it&#x27;s less productive and more risky.<p>10-15% of the productivity improvement is due to improvements in the dev environment. I open ~&#x2F;dotfiles with cursor and tell it a problem I have or ask for a specific improvement. It usually modifies .zshrc, .vimrc or similar (and iterates as necessary if the first attempt didn&#x27;t work). Due to how fast this is (e.g. 5 minutes), I&#x27;ve made about 20 little tweaks that previously didn&#x27;t justify the time. They definitely make me happier as well as a bit more productive.<p>But overall, taking everything into account, I&#x27;d say I&#x27;m about 2x as productive as before LLMs.", "url": "https://news.ycombinator.com/item?id=46409375", "hn_url": "https://news.ycombinator.com/item?id=46409375", "score": 30, "num_comments": 77, "created_utc": 1766909735, "author": "nomilk", "ai_tool": "Cursor", "scraped_at": "2025-12-28T17:12:32.369258"}
{"source": "HackerNews", "title": "Ask HN: Senior engineering mngrs: how has AI changed your day-to-day work?", "text": "Are you coding more or less, managing people differently, or making decisions in new ways because of AI tools? Which tools (LLMs, copilots, internal agents, analytics, etc.) have meaningfully stuck, and which turned out to be hype? I\u2019m especially interested in concrete changes to how you plan, review work, and support teams.", "url": "https://news.ycombinator.com/item?id=46565262", "hn_url": "https://news.ycombinator.com/item?id=46565262", "score": 10, "num_comments": 1, "created_utc": 1768049227, "author": "kitetm", "ai_tool": "Copilot", "scraped_at": "2026-01-10T17:12:28.475640"}
{"source": "HackerNews", "title": "Show HN: ChemistryLaTeX", "text": "I built a Chrome extension that renders 2D&#x2F;3D chemical structures directly on any webpage. It was originally designed to help with chemistry workflows in LLMs (like ChatGPT or Claude), where complex nomenclature is common but visual representation is often missing.\nHow it works:<p>It uses a regex-based trigger chem:mol=name: to detect chemical markup. You can also right-click any IUPAC name or common name (like &quot;benzene&quot;) to render it instantly.\nKey Technical Details:\nRendering: Uses a custom engine to generate bond-line diagrams.<p>3D View: Integrated 3D rendering for molecules, minerals, and biological assemblies (proteins&#x2F;viruses) from RCSB.\nPerformance: Implements SVG caching and lazy loading to ensure it doesn&#x27;t slow down the browser.\nPrivacy: Only processes text matching the specific trigger pattern &#x2F;\\bchem:([^:]+):&#x2F;g; no other page data is collected.\nI&#x27;d love to get your feedback on the rendering style and any suggestions for additional markup triggers that would be useful for scientific typesetting.", "url": "https://chromewebstore.google.com/detail/chemistrylatex/dkjdnddfiajiachpfgbkicoiodgomnoc", "hn_url": "https://news.ycombinator.com/item?id=46575423", "score": 2, "num_comments": 0, "created_utc": 1768136854, "author": "quintessen", "ai_tool": "Claude", "scraped_at": "2026-01-11T17:12:28.741865"}
{"source": "HackerNews", "title": "Show HN: Agentify Desktop: No-API Access to ChatGPT Pro Inside Codex", "text": "I got tired of copy pasting code and context back and forth between my codex &amp; chatgpt.com pro<p>My coding workflow happens locally in Codex. I wanted the reasoning power of the ChatGPT Pro model without the friction of context switching or paying double for API credits on massive context windows.<p>What it is:<p>Agentify Desktop is an Electron-based wrapper that exposes your active chatgpt.com session as an MCP (Model Context Protocol) server.<p>Core Features:<p><pre><code>    Web-to-CLI Bridge: You can prompt ChatGPT Web directly from your local Codex environment. It automates the browser interaction, handles file uploads, and returns the response to your terminal.\n\n    No API Keys: It uses your existing logged-in web session.\n\n    Bidirectional Orchestration (WIP): allows the reverse: you can drive your local Codex instance from the ChatGPT web chat. You can tell ChatGPT Web to &quot;plan and execute it on my codex cli(s),&quot; and it will trigger or you can do one way multiple codex cli instances).\n</code></pre>\nHow it works:<p>quickstart.sh installs, registers mcp to your codex by spinning up a local Electron browser that you log into. The MCP server connects to this browser instance. When you query it from Codex, it automates the input&#x2F;output in the web view.<p>Safety&#x2F;Limits:<p>This is designed for individual &quot;power user&quot; workflow (similar to other popular chatgpt.com automation tools), not bulk scraping . It includes rate limiting (token buckets) and concurrency limits to keep your account safe and avoid flagging spam filters. it doesn&#x27;t solve CAPTCHAs for you.<p>It\u2019s currently tested on Mac-only (I don&#x27;t have a Windows machine to test on yet) and definitely a work in progress. looking for feedback, i will add other sites like grok.com, aistudio.com, and more as requested.<p>Repo is here: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;agentify-sh&#x2F;desktop\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;agentify-sh&#x2F;des", "url": "https://news.ycombinator.com/item?id=46638415", "hn_url": "https://news.ycombinator.com/item?id=46638415", "score": 1, "num_comments": 0, "created_utc": 1768507593, "author": "agentifysh", "ai_tool": "ChatGPT", "scraped_at": "2026-01-16T17:19:40.158969"}
{"source": "HackerNews", "title": "Seen the same LLM prompt break invariants weeks later in prod?", "text": "I\u2019m asking specifically about LLM calls embedded inside real production workflows, not demos, side projects, or exploratory prompt work.<p>Think backend pipelines like:\nstep 1 \u2192 LLM \u2192 step 2 \u2192 LLM \u2192 step 3\nwhere users depend on the output and nothing technically \u201ccrashes.\u201d<p>We\u2019ve seen a recurring pattern:\n- Same input, same prompt, same model\n- Works reliably for weeks\n- Then a constraint is ignored, or a later step contradicts an earlier one\n- Retries don\u2019t reliably fix it\n- Logs don\u2019t explain what changed<p>The hardest part isn\u2019t bad output, it\u2019s not being able to explain failures to PMs or stakeholders when nothing obviously broke.<p>Curious how others operating LLM-backed workflows in production are diagnosing or containing this kind of behavior over time.<p>(Not looking for prompt advice or eval frameworks. Interested in operational experiences.)", "url": "https://news.ycombinator.com/item?id=46656449", "hn_url": "https://news.ycombinator.com/item?id=46656449", "score": 2, "num_comments": 2, "created_utc": 1768640447, "author": "ritwikkar", "ai_tool": "General", "scraped_at": "2026-01-17T17:12:29.494750"}
{"source": "HackerNews", "title": "Ask HN: What non-LLM tools have meaningfully improved your dev productivity?", "text": "Curious what tools people are using that aren&#x27;t GenAI&#x2F;LLM-based. Things that have actually changed how you work, not just minor conveniences.", "url": "https://news.ycombinator.com/item?id=46678980", "hn_url": "https://news.ycombinator.com/item?id=46678980", "score": 3, "num_comments": 2, "created_utc": 1768830799, "author": "primaprashant", "ai_tool": "General", "scraped_at": "2026-01-19T17:18:54.632954"}
{"source": "HackerNews", "title": "Ask HN: Have your views about AI / LLMs changed? What triggered it?", "text": "Curious how people&#x27;s views on AI&#x2F;LLMs have evolved over the last couple of years.", "url": "https://news.ycombinator.com/item?id=46713460", "hn_url": "https://news.ycombinator.com/item?id=46713460", "score": 4, "num_comments": 1, "created_utc": 1769040154, "author": "ATechGuy", "ai_tool": "General", "scraped_at": "2026-01-22T17:23:21.802426"}
{"source": "HackerNews", "title": "Tell HN: ChatGPT needs a persistent workspace layer", "text": "Many heavy ChatGPT users have shifted from \u201cconversation\u201d into \u201ccontinuous work\u201d: planning, research, writing, coordination, and decision-making.<p>But conversations evaporate. Tabs don\u2019t scale. Threads don\u2019t map to how humans manage multi-week commitments.<p>What\u2019s missing is a persistent workspace layer:<p>\u2014 account-level, not chat-level<p>\u2014 structured but lightweight<p>\u2014 model-aware (so the AI can reference context)<p>\u2014 opt-in (never intrusive)<p>\u2014 supports memory, plans, tasks, notes, drafts, decisions, and coordination<p>This would transform ChatGPT from an assistant for \u201cthis moment\u201d into a partner across time.<p>Curious if others feel this gap emerging \u2014 especially people using LLMs for long-term personal or professional workflows.", "url": "https://news.ycombinator.com/item?id=46711765", "hn_url": "https://news.ycombinator.com/item?id=46711765", "score": 8, "num_comments": 1, "created_utc": 1769030660, "author": "LostBeacon", "ai_tool": "ChatGPT", "scraped_at": "2026-01-22T17:23:21.802479"}
{"source": "HackerNews", "title": "Auto-compact not triggering on Claude.ai despite being marked as fixed", "text": "", "url": "https://github.com/anthropics/claude-code/issues/18866", "hn_url": "https://news.ycombinator.com/item?id=46736091", "score": 185, "num_comments": 171, "created_utc": 1769193758, "author": "nurimamedov", "ai_tool": "Claude", "scraped_at": "2026-01-24T17:13:01.190163"}
